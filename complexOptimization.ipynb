{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "bcd205ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IMPORT STATEMENTS ---\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from gurobipy import Model, GRB, quicksum, GurobiError\n",
    "from collections import deque\n",
    "\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "2203e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded civ_map_data.json successfully.\n",
      "Top 10 potential City Center coordinates selected:\n",
      "  1. (56, 25) (Score: 319.0000)\n",
      "  2. (11, 23) (Score: 271.0000)\n",
      "  3. (45, 31) (Score: 261.0000)\n",
      "  4. (52, 27) (Score: 261.0000)\n",
      "  5. (17, 18) (Score: 251.0000)\n",
      "  6. (56, 26) (Score: 242.0000)\n",
      "  7. (51, 22) (Score: 242.0000)\n",
      "  8. (48, 23) (Score: 242.0000)\n",
      "  9. (9, 10) (Score: 242.0000)\n",
      "  10. (13, 19) (Score: 232.0000)\n"
     ]
    }
   ],
   "source": [
    "# --- CIV 6 DISTRICT PLACEMENT OPTIMIZATION MODEL ---\n",
    "# Input sets / Data Initialization\n",
    "\n",
    "# parse input data from civ_map_data.json into a pandas dataframe\n",
    "try:\n",
    "    with open('civ_map_data.json') as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data['tiles'])\n",
    "    print(\"Loaded civ_map_data.json successfully.\")\n",
    "    # print(df.head())\n",
    "except FileNotFoundError: # ERROR CHECKING\n",
    "    print(\"ERROR: civ_map_data.json not found. Please ensure it's in the correct directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not load or parse civ_map_data.json: {e}\")\n",
    "\n",
    "\n",
    "# ... (previous code in Cell 2 for loading df) ...\n",
    "\n",
    "# --- Select Top N Tiles for Sensitivity Analysis ---\n",
    "N_TOP_TILES = 10 # You can change this value\n",
    "\n",
    "if 'normalized_score' in df.columns:\n",
    "    # Sort DataFrame by normalized_score in descending order and take top N\n",
    "    top_n_tiles_df = df.sort_values(by='normalized_score', ascending=False).head(N_TOP_TILES)\n",
    "\n",
    "    # Store coordinates of these top N tiles\n",
    "    potential_city_centers = []\n",
    "    for index, tile_row in top_n_tiles_df.iterrows():\n",
    "        potential_city_centers.append((int(tile_row['x']), int(tile_row['y'])))\n",
    "\n",
    "    if not potential_city_centers:\n",
    "        print(\"ERROR: No potential city centers found. Check 'normalized_score' in your data.\")\n",
    "        # Consider exiting or raising an error\n",
    "    else:\n",
    "        print(f\"Top {N_TOP_TILES} potential City Center coordinates selected:\")\n",
    "        for i, coords in enumerate(potential_city_centers):\n",
    "            score = top_n_tiles_df.iloc[i]['normalized_score']\n",
    "            print(f\"  {i+1}. {coords} (Score: {score:.4f})\")\n",
    "\n",
    "    city_center_coords = potential_city_centers[0] # select the very best for the single model\n",
    "    cc_x, cc_y = city_center_coords\n",
    "    # print(f\"Selected City Center coordinates: {city_center_coords}\")\n",
    "    # print(f\"City Center X: {cc_x}, Y: {cc_y}\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: 'normalized_score' column not found in DataFrame.\")\n",
    "    potential_city_centers = [] # Ensure it's defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "296f1c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 44 standard district adjacency pairs\n",
      "Constants and data structures defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Constants and Data Structures ---\n",
    "\n",
    "# Set of Districts to consider\n",
    "ALL_DISTRICTS = [\n",
    "    \"Campus\", \"Holy Site\", \"Harbor\", \"Government Plaza\",\n",
    "    \"Theater Square\", \"Entertainment Complex\", \"Commercial Hub\",\n",
    "    \"Industrial Zone\", \"Aqueduct\", \"Water Park\", \"Dam\", \"Canal\"\n",
    "]\n",
    "\n",
    "# Unique Districts (this is the same set for now. If we ever add the neighborhood, for example, this will change)\n",
    "DISTRICTS_UNIQUE = [\n",
    "     \"Campus\", \"Holy Site\", \"Harbor\", \"Government Plaza\",\n",
    "     \"Theater Square\", \"Entertainment Complex\", \"Commercial Hub\",\n",
    "     \"Industrial Zone\", \"Aqueduct\", \"Water Park\", \"Dam\", \"Canal\"\n",
    "]\n",
    "\n",
    "# Mutually Exclusive Sets\n",
    "DISTRICTS_MUTUALLY_EXCLUSIVE = [\n",
    "    {\"Entertainment Complex\", \"Water Park\"}\n",
    "]\n",
    "\n",
    "DISTRICT_BASE_VALUE = {\n",
    "    \"Campus\": 2.0,\n",
    "    \"Industrial Zone\": 2.0,\n",
    "    \"Commercial Hub\": 2.0,\n",
    "    \"Theater Square\": 2.0,\n",
    "    \"Holy Site\": 2.0,\n",
    "    \"Harbor\": 2.0,\n",
    "    \"Government Plaza\": 3.0 # Higher value since it provides adjacency to others\n",
    "    # Add values for other districts\n",
    "}\n",
    "\n",
    "# Features relevant for adjacency or placement\n",
    "FEATURES = {\n",
    "    \"Mountain\": [\"TERRAIN_GRASS_MOUNTAIN\", \"TERRAIN_DESERT_MOUNTAIN\", \"TERRAIN_PLAINS_MOUNTAIN\", \"TERRAIN_TUNDRA_MOUNTAIN\", \"TERRAIN_SNOW_MOUNTAIN\"],\n",
    "    \"Coast\": [\"TERRAIN_COAST\"],\n",
    "    \"River\": [\"River\"], # Placeholder for river logic\n",
    "    \"Lake\": [\"TERRAIN_LAKE\"],\n",
    "    \"Oasis\": [\"TERRAIN_DESERT_OASIS\"],\n",
    "    \"Geothermal Fissure\": [\"FEATURE_GEOTHERMAL_FISSURE\"],\n",
    "    \"Reef\": [\"FEATURE_REEF\"],\n",
    "    \"Woods\": [\"FEATURE_WOODS\"],\n",
    "    \"Rainforest\": [\"FEATURE_JUNGLE\"],\n",
    "    \"Marsh\": [\"FEATURE_MARSH\"],\n",
    "    \"Floodplains\": [\"FEATURE_FLOODPLAINS\", \"FEATURE_FLOODPLAINS_GRASSLAND\", \"FEATURE_FLOODPLAINS_PLAINS\"], # Added Floodplains\n",
    "    \"NaturalWonder\": [\"NaturalWonder\"], # Placeholder if you add specific NW logic\n",
    "    \"Wonder\": [\"Wonder\"], # Placeholder for Built Wonders if treated as features\n",
    "    \"Strategic\": [\"StrategicResource\"], # Placeholder\n",
    "    \"Luxury\": [\"LuxuryResource\"] # Placeholder\n",
    "}\n",
    "\n",
    "# Terrain Adjacency Bonuses\n",
    "TERRAIN_BONUS_VALUE = {\n",
    "    (\"Campus\", \"Mountain\"): 1, (\"Campus\", \"Reef\"): 2, (\"Campus\", \"Geothermal Fissure\"): 2,\n",
    "    (\"Campus\", \"Rainforest\"): 0.5,\n",
    "    (\"Holy Site\", \"Mountain\"): 1, (\"Holy Site\", \"Woods\"): 0.5,\n",
    "    (\"Holy Site\", \"Natural Wonder\"): 2, # Assumes \"NaturalWonder\" feature exists\n",
    "    (\"Commercial Hub\", \"River\"): 2,     # Handled by river logic later\n",
    "    (\"Theater Square\", \"Wonder\"): 2,      # Assumes \"Wonder\" feature exists for built wonders\n",
    "    (\"Industrial Zone\", \"Strategic\"): 1, # Example if needed\n",
    "    (\"Aqueduct\", \"Geothermal Fissure\"): 2, # Example bonus TO aqueduct\n",
    "    # Note: River bonus for CH is handled separately based on river edge data\n",
    "}\n",
    "# Ensure \"River\" key exists if used for CH bonus calculation later\n",
    "RIVER_FEATURE_KEY = \"River\"\n",
    "\n",
    "# City Center Adjacency Bonuses\n",
    "CC_BONUS_VALUE = { \"Harbor\": 2 } # Default others to 0 later\n",
    "\n",
    "# District-to-District Adjacency Bonuses\n",
    "# Format: (District Receiving Bonus, Adjacent District/Feature Providing Bonus): Bonus Value\n",
    "DISTRICT_PAIR_BONUS = {\n",
    "    # --- Original Pairs ---\n",
    "    ('Commercial Hub', 'Harbor'): 2,\n",
    "    \n",
    "    # ('Theater Square', 'Wonder'): 2, # Covered by TERRAIN_BONUS_VALUE if Wonder is a Feature\n",
    "    ('Theater Square', 'Entertainment Complex'): 1,\n",
    "    ('Theater Square', 'Water Park'): 1,\n",
    "    ('Industrial Zone', 'Aqueduct'): 2,\n",
    "    ('Industrial Zone', 'Dam'): 2,\n",
    "    ('Industrial Zone', 'Canal'): 2,\n",
    "    # --- Government Plaza Provided Bonuses ---\n",
    "    ('Campus',          'Government Plaza'): 1, # <--- Set back to 1 (or 10 for testing)\n",
    "    ('Holy Site',       'Government Plaza'): 1,\n",
    "    ('Harbor',          'Government Plaza'): 1,\n",
    "    ('Commercial Hub',  'Government Plaza'): 1,\n",
    "    ('Industrial Zone', 'Government Plaza'): 1,\n",
    "    ('Theater Square',  'Government Plaza'): 1,\n",
    "}\n",
    "\n",
    "# Generate standard district adjacency bonuses (0.5 for any district pair)\n",
    "def generate_standard_district_adjacencies():\n",
    "    standard_pairs = {}\n",
    "    # Districts that receive adjacency from any district\n",
    "    receiving_districts = [\"Campus\", \"Holy Site\", \"Theater Square\", \"Industrial Zone\", \"Commercial Hub\"]\n",
    "    \n",
    "    for receiving in receiving_districts:\n",
    "        for giving in ALL_DISTRICTS:\n",
    "            # Skip if it's the same district or if a specific bonus already exists\n",
    "            if receiving != giving and (receiving, giving) not in DISTRICT_PAIR_BONUS:\n",
    "                standard_pairs[(receiving, giving)] = 0.5\n",
    "    \n",
    "    return standard_pairs\n",
    "\n",
    "# Extend DISTRICT_PAIR_BONUS with standard adjacencies\n",
    "STANDARD_DISTRICT_ADJACENCIES = generate_standard_district_adjacencies()\n",
    "DISTRICT_PAIR_BONUS.update(STANDARD_DISTRICT_ADJACENCIES)\n",
    "print(f\"Added {len(STANDARD_DISTRICT_ADJACENCIES)} standard district adjacency pairs\")\n",
    "\n",
    "# Default CC Bonus to 0 for districts not listed\n",
    "for dist in ALL_DISTRICTS: CC_BONUS_VALUE.setdefault(dist, 0)\n",
    "\n",
    "# Other Constants\n",
    "RADIUS = 3\n",
    "MAX_ADJACENT_TILES = 6 # Max neighbors in hex grid\n",
    "\n",
    "IMPASSABLE_TERRAIN = {\n",
    "    \"TERRAIN_OCEAN\", \"TERRAIN_GRASS_MOUNTAIN\", \"TERRAIN_DESERT_MOUNTAIN\", \"TERRAIN_PLAINS_MOUNTAIN\",\n",
    "    \"TERRAIN_TUNDRA_MOUNTAIN\", \"TERRAIN_SNOW_MOUNTAIN\", \"TERRAIN_LAKE\",\n",
    "}\n",
    "IMPASSABLE_FEATURES = { \"FEATURE_ICE\" }\n",
    "\n",
    "\n",
    "# Map yields to their primary districts\n",
    "YIELD_TO_DISTRICT = {\n",
    "    \"science\": \"Campus\",\n",
    "    \"culture\": \"Theater Square\",\n",
    "    \"production\": \"Industrial Zone\",\n",
    "    \"gold\": \"Commercial Hub\",\n",
    "    \"faith\": \"Holy Site\",\n",
    "    \"food\": \"None\",  # No direct district, but affects overall strategy\n",
    "}\n",
    "\n",
    "# Create priority profiles with district value multipliers\n",
    "def create_priority_profile(primary_yield, boost_factor=2.0):\n",
    "    \"\"\"Creates a district priority profile based on primary yield\"\"\"\n",
    "    profile = {}\n",
    "    \n",
    "    # Set baseline values for all districts\n",
    "    for district in ALL_DISTRICTS:\n",
    "        if district == YIELD_TO_DISTRICT.get(primary_yield):\n",
    "            # Primary district gets boosted value\n",
    "            profile[district] = DISTRICT_BASE_VALUE.get(district, 1.0) * boost_factor\n",
    "        elif district == \"Industrial Zone\" and primary_yield != \"production\":\n",
    "            # Production helps everything, so IZ still gets a small boost\n",
    "            profile[district] = DISTRICT_BASE_VALUE.get(district, 1.0) * 1.2\n",
    "        elif district == \"Government Plaza\":\n",
    "            # GP always valuable for adjacency bonuses\n",
    "            profile[district] = DISTRICT_BASE_VALUE.get(district, 3.0)\n",
    "        else:\n",
    "            # Other districts get normal values\n",
    "            profile[district] = DISTRICT_BASE_VALUE.get(district, 1.0)\n",
    "            \n",
    "    return profile\n",
    "\n",
    "print(\"Constants and data structures defined.\")\n",
    "# print(\"Checking DISTRICT_PAIR_BONUS for ('Campus', 'Government Plaza'):\", DISTRICT_PAIR_BONUS.get(('Campus', 'Government Plaza'), 'MISSING')) # Debug check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "6fe8e384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Helper Functions ---\n",
    "\n",
    "def get_adjacent_tiles(x, y, all_map_coords_set):\n",
    "    \"\"\" Gets coordinates of adjacent tiles based on 'odd-r' flat-top logic. \"\"\"\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    direct_offsets = []\n",
    "    is_even_row = y % 2 == 0\n",
    "\n",
    "    if is_even_row: # EVEN rows (y=0, 2, 4...)\n",
    "        direct_offsets = [ [+1,  0], [+1, +1], [ 0, +1], [-1,  0], [ 0, -1], [+1, -1] ]\n",
    "    else: # ODD rows (y=1, 3, 5...)\n",
    "        direct_offsets = [ [+1,  0], [ 0, +1], [-1, +1], [-1,  0], [-1, -1], [ 0, -1] ]\n",
    "\n",
    "    adjacent = set()\n",
    "    for dx, dy in direct_offsets:\n",
    "        neighbor_coords = (x + dx, y + dy)\n",
    "        if neighbor_coords in all_map_coords_set:\n",
    "            adjacent.add(neighbor_coords)\n",
    "    return adjacent\n",
    "\n",
    "def get_tiles_in_radius_bfs(start_coords, max_rings, all_map_coords_set):\n",
    "    \"\"\" Finds all tiles within max_rings steps from start_coords using BFS. \"\"\"\n",
    "    start_x, start_y = int(start_coords[0]), int(start_coords[1])\n",
    "    start_coords_int = (start_x, start_y)\n",
    "\n",
    "    if start_coords_int not in all_map_coords_set:\n",
    "        print(f\"Warning: Start coordinates {start_coords_int} not in map data.\")\n",
    "        return set()\n",
    "    if max_rings <= 0: return {start_coords_int}\n",
    "\n",
    "    queue = deque([(start_coords_int, 0)])\n",
    "    visited = {start_coords_int}\n",
    "    reachable_tiles = {start_coords_int}\n",
    "\n",
    "    while queue:\n",
    "        current_coords, current_dist = queue.popleft()\n",
    "        if current_dist < max_rings:\n",
    "            neighbors = get_adjacent_tiles(current_coords[0], current_coords[1], all_map_coords_set)\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    reachable_tiles.add(neighbor)\n",
    "                    queue.append((neighbor, current_dist + 1))\n",
    "    return reachable_tiles\n",
    "\n",
    "print(\"Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "88c94a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tiles in radius 3: 37\n",
      "Workable tiles in radius: 29\n",
      "Tiles with river edges identified: 10\n"
     ]
    }
   ],
   "source": [
    "# --- Pre-calculation Steps ---\n",
    "\n",
    "# Set of all valid (x, y) coordinates from the DataFrame\n",
    "all_map_coords = set((int(coord[0]), int(coord[1])) for coord in df[['x', 'y']].values)\n",
    "\n",
    "# Tiles: Set of tiles within the defined radius using BFS\n",
    "tiles_in_radius = get_tiles_in_radius_bfs(city_center_coords, RADIUS, all_map_coords)\n",
    "print(f\"Total tiles in radius {RADIUS}: {len(tiles_in_radius)}\")\n",
    "if not tiles_in_radius:\n",
    "     print(\"ERROR: No tiles found within radius. Check CC coords and map data.\")\n",
    "     # exit()\n",
    "\n",
    "# Mapping from (x, y) tuple to the tile's data (only for tiles in radius)\n",
    "tile_data = {\n",
    "    (int(row['x']), int(row['y'])): row for index, row in df.iterrows()\n",
    "    if (int(row['x']), int(row['y'])) in tiles_in_radius\n",
    "}\n",
    "\n",
    "# Tiles_Workable: Subset of tiles_in_radius where districts can potentially be built\n",
    "tiles_workable = set()\n",
    "coast_terrain_values = FEATURES.get(\"Coast\", [\"TERRAIN_COAST\"]) # Get list of coast terrain types\n",
    "for coords in tiles_in_radius:\n",
    "    if coords == city_center_coords: continue\n",
    "    if coords not in tile_data: continue\n",
    "\n",
    "    tile_info = tile_data[coords]\n",
    "    terrain = tile_info['terrain']\n",
    "    feature = tile_info.get('feature') # Use .get for features which might be null\n",
    "\n",
    "    is_impassable_terrain = terrain in IMPASSABLE_TERRAIN\n",
    "    is_impassable_feature = feature is not None and feature in IMPASSABLE_FEATURES\n",
    "    is_impassable = is_impassable_terrain or is_impassable_feature\n",
    "\n",
    "    # Allow placement on Coast tiles (for Harbor), otherwise check impassable\n",
    "    if terrain in coast_terrain_values or not is_impassable:\n",
    "         # Add further checks if needed (e.g., some features block certain districts)\n",
    "         tiles_workable.add(coords)\n",
    "\n",
    "print(f\"Workable tiles in radius: {len(tiles_workable)}\")\n",
    "\n",
    "# Adjacency Map: Maps (x, y) -> set of adjacent (x', y') within the radius\n",
    "adjacency_map = {\n",
    "    coords: get_adjacent_tiles(coords[0], coords[1], all_map_coords).intersection(tiles_in_radius)\n",
    "    for coords in tiles_in_radius\n",
    "}\n",
    "\n",
    "# Features on Tile Map & River Adjacency Map\n",
    "features_on_tile = {}\n",
    "has_river_edge = {} # Maps (x, y) -> boolean, True if tile itself has river edge data\n",
    "\n",
    "for coords in tiles_in_radius:\n",
    "    if coords not in tile_data: continue\n",
    "    tile_info = tile_data[coords]\n",
    "    tile_features = set() # Features relevant for providing bonuses (Mountain, Reef etc)\n",
    "\n",
    "    terrain = tile_info['terrain']\n",
    "    feature = tile_info.get('feature')\n",
    "    resource = tile_info.get('resource')\n",
    "    res_type = tile_info.get('resourcetype', '') # Default to empty string\n",
    "    is_nw = tile_info.get('isNaturalWonder', False) # Assumes boolean flag exists\n",
    "    # Add check for built Wonders if needed e.g., tile_info.get('isWonderBuilt', False)\n",
    "\n",
    "    # Map terrain/feature names from FEATURES constant (excluding River, NW, Wonder, Resources)\n",
    "    # These provide adjacency bonus\n",
    "    for f_name, f_data_vals in FEATURES.items():\n",
    "        # Handle bonus-providing features based on *their* terrain/feature type\n",
    "         if f_name not in {\"River\", \"NaturalWonder\", \"Wonder\", \"Strategic\", \"Luxury\", \"Floodplains\", \"Coast\", \"Lake\", \"Oasis\"}: # Exclude types handled differently or non-bonus giving terrain itself\n",
    "              if terrain in f_data_vals or (feature is not None and feature in f_data_vals):\n",
    "                   tile_features.add(f_name)\n",
    "\n",
    "    # Add special feature flags to the set for the tile itself\n",
    "    if is_nw: tile_features.add(\"NaturalWonder\")\n",
    "    # if tile_info.get('isWonderBuilt', False): tile_features.add(\"Wonder\") # Add if you track built wonders this way\n",
    "    if resource:\n",
    "        if res_type is not None:\n",
    "            if res_type.lower() == 'strategic': tile_features.add(\"Strategic\")\n",
    "            elif res_type.lower() == 'luxury': tile_features.add(\"Luxury\")\n",
    "\n",
    "    features_on_tile[coords] = tile_features\n",
    "\n",
    "    # River Edge Check (Crucial for River Bonus)\n",
    "    # Assumes 'rivers' field exists and is non-empty string/list/dict if river is present\n",
    "    if pd.notna(tile_info.get('rivers')) and tile_info.get('rivers') not in [\"\", None, [], {}]:\n",
    "        has_river_edge[coords] = True\n",
    "    else:\n",
    "        has_river_edge[coords] = False\n",
    "\n",
    "print(f\"Tiles with river edges identified: {sum(has_river_edge.values())}\")\n",
    "# print({k: v for k, v in has_river_edge.items() if v}) # Optional: Print tiles with rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "id": "19035a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function for Pre-calculation Steps ---\n",
    "# This function encapsulates the logic primarily found in Cell 5, to allow numerous city centers calculate their own pre-calculations for sensitivity analysis\n",
    "\n",
    "def perform_pre_calculations(cc_coords, df_all_tiles, radius_val, all_districts_list, features_dict,\n",
    "                             impassable_terrain_set, impassable_features_set, river_feature_key_str):\n",
    "    \"\"\"\n",
    "    Performs all necessary pre-calculations based on a given city center.\n",
    "    This function encapsulates the logic primarily found in Cell 5.\n",
    "    \"\"\"\n",
    "    current_city_center_coords = (int(cc_coords[0]), int(cc_coords[1]))\n",
    "\n",
    "    # Set of all valid (x, y) coordinates from the DataFrame\n",
    "    all_map_coords = set((int(coord[0]), int(coord[1])) for coord in df_all_tiles[['x', 'y']].values)\n",
    "\n",
    "    # Tiles: Set of tiles within the defined radius using BFS\n",
    "    current_tiles_in_radius = get_tiles_in_radius_bfs(current_city_center_coords, radius_val, all_map_coords)\n",
    "    print(f\"For CC at {current_city_center_coords}: Total tiles in radius {radius_val}: {len(current_tiles_in_radius)}\")\n",
    "    if not current_tiles_in_radius:\n",
    "         print(f\"ERROR: No tiles found within radius for CC {current_city_center_coords}.\")\n",
    "         return None # Or raise an error\n",
    "\n",
    "    # Mapping from (x, y) tuple to the tile's data (only for tiles in radius)\n",
    "    current_tile_data = {\n",
    "        (int(row['x']), int(row['y'])): row for index, row in df_all_tiles.iterrows()\n",
    "        if (int(row['x']), int(row['y'])) in current_tiles_in_radius\n",
    "    }\n",
    "\n",
    "    # Tiles_Workable: Subset of tiles_in_radius where districts can potentially be built\n",
    "    current_tiles_workable = set()\n",
    "    coast_terrain_values_list = features_dict.get(\"Coast\", [\"TERRAIN_COAST\"])\n",
    "    for coords in current_tiles_in_radius:\n",
    "        if coords == current_city_center_coords: continue\n",
    "        if coords not in current_tile_data: continue\n",
    "\n",
    "        tile_info = current_tile_data[coords]\n",
    "        terrain = tile_info['terrain']\n",
    "        feature = tile_info.get('feature')\n",
    "\n",
    "        is_impassable_terrain = terrain in impassable_terrain_set\n",
    "        is_impassable_feature = feature is not None and feature in impassable_features_set\n",
    "        is_impassable = is_impassable_terrain or is_impassable_feature\n",
    "\n",
    "        if terrain in coast_terrain_values_list or not is_impassable:\n",
    "             current_tiles_workable.add(coords)\n",
    "    print(f\"For CC at {current_city_center_coords}: Workable tiles in radius: {len(current_tiles_workable)}\")\n",
    "\n",
    "    # Adjacency Map\n",
    "    current_adjacency_map = {\n",
    "        coords: get_adjacent_tiles(coords[0], coords[1], all_map_coords).intersection(current_tiles_in_radius)\n",
    "        for coords in current_tiles_in_radius\n",
    "    }\n",
    "\n",
    "    # Features on Tile Map & River Adjacency Map\n",
    "    current_features_on_tile = {}\n",
    "    current_has_river_edge = {}\n",
    "    for coords in current_tiles_in_radius:\n",
    "        if coords not in current_tile_data: continue\n",
    "        tile_info = current_tile_data[coords]\n",
    "        tile_features = set()\n",
    "        terrain = tile_info['terrain']\n",
    "        feature = tile_info.get('feature')\n",
    "        resource = tile_info.get('resource')\n",
    "        res_type = tile_info.get('resourcetype', '')\n",
    "        is_nw = tile_info.get('isNaturalWonder', False)\n",
    "\n",
    "        for f_name, f_data_vals in features_dict.items():\n",
    "             if f_name not in {\"River\", \"NaturalWonder\", \"Wonder\", \"Strategic\", \"Luxury\", \"Floodplains\", \"Coast\", \"Lake\", \"Oasis\"}:\n",
    "                  if terrain in f_data_vals or (feature is not None and feature in f_data_vals):\n",
    "                       tile_features.add(f_name)\n",
    "        if is_nw: tile_features.add(\"NaturalWonder\")\n",
    "        if resource:\n",
    "            if res_type is not None:\n",
    "                if res_type.lower() == 'strategic': tile_features.add(\"Strategic\")\n",
    "                elif res_type.lower() == 'luxury': tile_features.add(\"Luxury\")\n",
    "        current_features_on_tile[coords] = tile_features\n",
    "        if pd.notna(tile_info.get('rivers')) and tile_info.get('rivers') not in [\"\", None, [], {}]:\n",
    "            current_has_river_edge[coords] = True\n",
    "        else:\n",
    "            current_has_river_edge[coords] = False\n",
    "    print(f\"For CC at {current_city_center_coords}: Tiles with river edges: {sum(current_has_river_edge.values())}\")\n",
    "\n",
    "    # --- Pre-calculation of Boolean Maps (from Cell 6) ---\n",
    "    current_is_adjacent_to_cc = {\n",
    "        coords: current_city_center_coords in current_adjacency_map.get(coords, set())\n",
    "        for coords in current_tiles_workable\n",
    "    }\n",
    "    freshwater_feature_keys_set = {\"River\", \"Lake\", \"Oasis\", \"Mountain\"}\n",
    "    current_is_adjacent_to_freshwater = {}\n",
    "    for coords in current_tiles_workable:\n",
    "        adj_fresh = False\n",
    "        for adj_coords in current_adjacency_map.get(coords, set()):\n",
    "             if adj_coords in current_tile_data:\n",
    "                  adj_tile_info = current_tile_data[adj_coords]\n",
    "                  adj_terrain = adj_tile_info['terrain']\n",
    "                  adj_feature = adj_tile_info.get('feature')\n",
    "                  if any(f_key in features_dict and (adj_terrain in features_dict[f_key] or \\\n",
    "                         (adj_feature is not None and adj_feature in features_dict[f_key])) \\\n",
    "                         for f_key in {\"Mountain\", \"Lake\", \"Oasis\"}):\n",
    "                       adj_fresh = True; break\n",
    "                  if current_has_river_edge.get(coords, False):\n",
    "                       adj_fresh = True; break\n",
    "        current_is_adjacent_to_freshwater[coords] = adj_fresh\n",
    "\n",
    "    current_is_coast = {\n",
    "        coords: current_tile_data[coords]['terrain'] in coast_terrain_values_list\n",
    "        for coords in current_tiles_workable if coords in current_tile_data\n",
    "    }\n",
    "    land_terrains_set = { t for t in df_all_tiles['terrain'].unique() if t not in {\"TERRAIN_OCEAN\", \"TERRAIN_COAST\", \"TERRAIN_LAKE\"} }\n",
    "    current_is_adjacent_to_land = {}\n",
    "    for coords in current_tiles_workable:\n",
    "        if current_is_coast.get(coords, False):\n",
    "            adj_land = False\n",
    "            for adj_coords in current_adjacency_map.get(coords, set()):\n",
    "                 if adj_coords in current_tile_data and current_tile_data[adj_coords]['terrain'] in land_terrains_set:\n",
    "                      adj_land = True; break\n",
    "            current_is_adjacent_to_land[coords] = adj_land\n",
    "        else:\n",
    "            current_is_adjacent_to_land[coords] = False\n",
    "\n",
    "    floodplains_feature_values_list = features_dict.get(\"Floodplains\", [])\n",
    "    current_is_floodplains = {\n",
    "         coords: current_tile_data[coords].get('feature') in floodplains_feature_values_list\n",
    "         for coords in current_tiles_workable if coords in current_tile_data\n",
    "    }\n",
    "    print(f\"For CC at {current_city_center_coords}: Pre-calculation of boolean maps finished.\")\n",
    "\n",
    "    return {\n",
    "        \"city_center_coords\": current_city_center_coords,\n",
    "        \"tiles_in_radius\": current_tiles_in_radius,\n",
    "        \"tile_data\": current_tile_data,\n",
    "        \"tiles_workable\": current_tiles_workable,\n",
    "        \"adjacency_map\": current_adjacency_map,\n",
    "        \"features_on_tile\": current_features_on_tile,\n",
    "        \"has_river_edge\": current_has_river_edge,\n",
    "        \"is_adjacent_to_cc\": current_is_adjacent_to_cc,\n",
    "        \"is_adjacent_to_freshwater\": current_is_adjacent_to_freshwater,\n",
    "        \"is_coast\": current_is_coast,\n",
    "        \"is_adjacent_to_land\": current_is_adjacent_to_land,\n",
    "        \"is_floodplains\": current_is_floodplains\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "94dfd996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-calculation of boolean maps finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Pre-calculation of Boolean Maps & Adjacency ---\n",
    "\n",
    "# isAdjacentToCC: Check adjacency for workable tiles\n",
    "is_adjacent_to_cc = {\n",
    "    coords: city_center_coords in adjacency_map.get(coords, set())\n",
    "    for coords in tiles_workable\n",
    "}\n",
    "\n",
    "# isAdjacentToFreshwater: Check adjacency for workable tiles\n",
    "# Freshwater sources: River, Lake, Oasis, Mountain (for Aqueduct)\n",
    "freshwater_feature_keys = {\"River\", \"Lake\", \"Oasis\", \"Mountain\"}\n",
    "is_adjacent_to_freshwater = {}\n",
    "for coords in tiles_workable:\n",
    "    adj_fresh = False\n",
    "    for adj_coords in adjacency_map.get(coords, set()):\n",
    "         # Check if adjacent tile IS a freshwater source (Lake/Oasis TILE or Mountain TILE)\n",
    "         # or if the current tile has a river edge crossing to the neighbor\n",
    "         if adj_coords in tile_data:\n",
    "              adj_tile_info = tile_data[adj_coords]\n",
    "              adj_terrain = adj_tile_info['terrain']\n",
    "              adj_feature = adj_tile_info.get('feature')\n",
    "\n",
    "              # Check Mountain, Lake, Oasis terrain/feature on adjacent tile\n",
    "              if any(f_key in FEATURES and (adj_terrain in FEATURES[f_key] or (adj_feature is not None and adj_feature in FEATURES[f_key])) for f_key in {\"Mountain\", \"Lake\", \"Oasis\"}):\n",
    "                   adj_fresh = True\n",
    "                   break\n",
    "              # Check if THIS tile has a river edge (more reliable than checking if neighbor IS river)\n",
    "              if has_river_edge.get(coords, False):\n",
    "                   adj_fresh = True\n",
    "                   break # Found freshwater source (river edge)\n",
    "    is_adjacent_to_freshwater[coords] = adj_fresh\n",
    "\n",
    "\n",
    "# isCoast: Check terrain for workable tiles\n",
    "coast_terrain_values = FEATURES.get(\"Coast\", [\"TERRAIN_COAST\"])\n",
    "is_coast = {\n",
    "    coords: tile_data[coords]['terrain'] in coast_terrain_values\n",
    "    for coords in tiles_workable if coords in tile_data\n",
    "}\n",
    "\n",
    "# isAdjacentToLand: Check adjacency for workable tiles (primarily for Harbor)\n",
    "# Define land terrains (anything not Ocean, Coast, Lake - adjust if needed)\n",
    "land_terrains = { t for t in df['terrain'].unique() if t not in {\"TERRAIN_OCEAN\", \"TERRAIN_COAST\", \"TERRAIN_LAKE\"} }\n",
    "is_adjacent_to_land = {}\n",
    "for coords in tiles_workable:\n",
    "    # Only relevant if the tile itself is Coast\n",
    "    if is_coast.get(coords, False):\n",
    "        adj_land = False\n",
    "        for adj_coords in adjacency_map.get(coords, set()):\n",
    "             if adj_coords in tile_data and tile_data[adj_coords]['terrain'] in land_terrains:\n",
    "                  adj_land = True\n",
    "                  break\n",
    "        is_adjacent_to_land[coords] = adj_land\n",
    "    else:\n",
    "        is_adjacent_to_land[coords] = False # Not relevant if the tile itself isn't Coast\n",
    "\n",
    "# isFloodplains: Check feature for workable tiles (for Dam)\n",
    "floodplains_feature_values = FEATURES.get(\"Floodplains\", [])\n",
    "is_floodplains = {\n",
    "     coords: tile_data[coords].get('feature') in floodplains_feature_values\n",
    "     for coords in tiles_workable if coords in tile_data\n",
    "}\n",
    "\n",
    "print(\"Pre-calculation of boolean maps finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "55b7e0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter OutputFlag to value 1\n",
      "Gurobi model initialized.\n"
     ]
    }
   ],
   "source": [
    "# --- Initialize Gurobi Model ---\n",
    "model = Model(\"Civ6_District_Optimization\")\n",
    "model.setParam('OutputFlag', 1) # Set to 1 for solver output, 0 to suppress\n",
    "print(\"Gurobi model initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "91512790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating main 'Build' variables...\n",
      "Gurobi 'Build' variables defined (348 variables).\n"
     ]
    }
   ],
   "source": [
    "# --- Define Main Decision Variables: Build(x, y, d) ---\n",
    "build_vars = {}\n",
    "print(\"Creating main 'Build' variables...\")\n",
    "for coords in tiles_workable:\n",
    "    for d in ALL_DISTRICTS:\n",
    "        var_name = f\"Build[{coords[0]},{coords[1]},{d}]\"\n",
    "        build_vars[coords, d] = model.addVar(vtype=GRB.BINARY, name=var_name)\n",
    "\n",
    "# Integrate new variables immediately (good practice)\n",
    "model.update()\n",
    "print(f\"Gurobi 'Build' variables defined ({len(build_vars)} variables).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "a004c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining auxiliary adjacency variables...\n",
      "Defined 1624 auxiliary adjacency variables.\n",
      "*** CRITICAL WARNING: Key ((51, 16), 'Campus', 'Government Plaza') DOES NOT EXIST in adj_district_vars after creation loop! ***\n"
     ]
    }
   ],
   "source": [
    "# --- Define Auxiliary Variables for District Adjacency ---\n",
    "adj_district_vars = {} # Format: adj_district_vars[coords_d1, d1, d2] = variable A\n",
    "\n",
    "print(\"Defining auxiliary adjacency variables...\")\n",
    "# Create variables only for pairs defined in DISTRICT_PAIR_BONUS where d1 receives bonus from d2\n",
    "for (d1, d2), bonus_value in DISTRICT_PAIR_BONUS.items():\n",
    "    if bonus_value > 0:\n",
    "        # Check if d2 is a district type or a feature like 'Wonder'\n",
    "        is_d2_district = d2 in ALL_DISTRICTS\n",
    "        is_d2_feature = d2 in FEATURES # e.g., 'Wonder' if handled as feature\n",
    "\n",
    "        for coords_d1 in tiles_workable:\n",
    "            # Ensure the primary district (d1) variable exists for this tile\n",
    "            if (coords_d1, d1) in build_vars:\n",
    "                 # Create the aux variable: AdjDist_x_y_d1_from_d2 = 1 if d1 at (x,y) gets bonus from adjacent d2\n",
    "                 var_name = f\"AdjDist_{coords_d1[0]}_{coords_d1[1]}_{d1}_from_{d2}\"\n",
    "                 # Use tuple key: (coords_tuple, d1_string, d2_string)\n",
    "                 current_key = (coords_d1, d1, d2) # Define the key explicitly\n",
    "                 adj_district_vars[current_key] = model.addVar(vtype=GRB.BINARY, name=var_name)\n",
    "\n",
    "                 # --- Add specific debug print for variable creation ---\n",
    "                 if coords_d1 == (51, 16) and d1 == 'Campus' and d2 == 'Government Plaza':\n",
    "                      print(f\"\\n*** DEBUG: SUCCESSFULLY CREATED aux var for key {current_key} with name {var_name} ***\\n\")\n",
    "                 # --- End debug print ---\n",
    "\n",
    "\n",
    "# Integrate new variables\n",
    "model.update()\n",
    "print(f\"Defined {len(adj_district_vars)} auxiliary adjacency variables.\")\n",
    "# Check if the specific key exists AFTER the loop\n",
    "check_key = ((51, 16), 'Campus', 'Government Plaza')\n",
    "if check_key in adj_district_vars:\n",
    "    print(f\"DEBUG: Key {check_key} EXISTS in adj_district_vars after creation loop.\")\n",
    "else:\n",
    "    print(f\"*** CRITICAL WARNING: Key {check_key} DOES NOT EXIST in adj_district_vars after creation loop! ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "404690c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding linking constraints for adjacency variables...\n",
      "Added 0 linking constraints for adjacency.\n"
     ]
    }
   ],
   "source": [
    "# --- Add Linking Constraints for Auxiliary Adjacency Variables ---\n",
    "# Links A = adj_district_vars[coords_d1, d1, d2]\n",
    "# To B1 = build_vars[coords_d1, d1]\n",
    "# And S2 = Sum over adjacent tiles (adj_coords) of Build(adj_coords, d2) or HasFeature(adj_coords, d2)\n",
    "\n",
    "print(\"Adding linking constraints for adjacency variables...\")\n",
    "constraints_added_count = 0\n",
    "\n",
    "for (coords_d1, d1, d2), A in adj_district_vars.items():\n",
    "    # Get the B1 variable (Build(d1) at coords_d1)\n",
    "    if (coords_d1, d1) not in build_vars: continue # Should not happen based on creation logic, but safe check\n",
    "    B1 = build_vars[coords_d1, d1]\n",
    "\n",
    "    # Calculate S2 = Sum of adjacent triggers (d2)\n",
    "    adjacent_tiles = adjacency_map.get(coords_d1, set())\n",
    "    sum_expr_S2 = None # Initialize S2 expression\n",
    "\n",
    "    # Determine if d2 is a District or a Feature triggering the bonus\n",
    "    if d2 in ALL_DISTRICTS:\n",
    "         # S2 is the sum of Build(adj_coords, d2) for adjacent workable tiles\n",
    "         # Use a list comprehension inside quicksum for clarity if needed\n",
    "         s2_terms = [build_vars.get((adj_coords, d2), 0)\n",
    "                     for adj_coords in adjacent_tiles\n",
    "                     if adj_coords in tiles_workable and (adj_coords, d2) in build_vars] # Ensure var exists\n",
    "         sum_expr_S2 = quicksum(s2_terms)\n",
    "\n",
    "    elif d2 in FEATURES: # Check if d2 is a key in FEATURES dict (e.g., \"Wonder\")\n",
    "         # S2 is the sum of indicator constants (1 if feature present, 0 otherwise)\n",
    "         sum_expr_S2 = quicksum(1\n",
    "                                for adj_coords in adjacent_tiles\n",
    "                                if adj_coords in features_on_tile and d2 in features_on_tile[adj_coords])\n",
    "    else:\n",
    "         # Skip if d2 is not a district or known feature key\n",
    "         continue\n",
    "\n",
    "    # --- DEBUG PRINT for S2 expression (Now Included) ---\n",
    "    if d1 == 'Campus' and d2 == 'Government Plaza' and coords_d1 == (51, 16): # Check for specific Campus location\n",
    "         print(f\"\\n*** DEBUG constraint S2 check for Campus at {coords_d1} from GP: ***\")\n",
    "         try:\n",
    "              # Check if S2 is a valid Gurobi expression type\n",
    "              if isinstance(sum_expr_S2, (int, float, type(None))): # Check if it resolved to a constant or None\n",
    "                   print(f\"  S2 Expression evaluated to constant/None: {sum_expr_S2}\")\n",
    "              else: # Assume it's a Gurobi LinExpr\n",
    "                   print(f\"  S2 Expression (Gurobi): {sum_expr_S2}\")\n",
    "\n",
    "              # Check components manually to see which vars S2 depends on\n",
    "              terms = []\n",
    "              s2_term_vars_found = False\n",
    "              for adj_coords_debug in adjacency_map.get(coords_d1, set()):\n",
    "                    if adj_coords_debug in tiles_workable:\n",
    "                         key_debug = (adj_coords_debug, 'Government Plaza')\n",
    "                         if key_debug in build_vars:\n",
    "                              terms.append(build_vars[key_debug].VarName)\n",
    "                              s2_term_vars_found = True\n",
    "              print(f\"  S2 depends on GP Build Vars on workable adjacent tiles: {terms if s2_term_vars_found else '*** NONE FOUND - THIS IS LIKELY THE PROBLEM ***'}\")\n",
    "         except Exception as e:\n",
    "              print(f\"  Error printing S2 expression/components: {e}\")\n",
    "         print(\"*** End S2 Check ***\\n\")\n",
    "    # --- End S2 Debug Print ---\n",
    "\n",
    "\n",
    "    # --- Constraints linking A to B1 and S2: A = 1 iff B1=1 and S2>=1 ---\n",
    "    constr_name_base = f\"LinkAdj_{coords_d1[0]}_{coords_d1[1]}_{d1}_{d2}\"\n",
    "\n",
    "    # Check if sum_expr_S2 is valid before adding constraints using it\n",
    "    if sum_expr_S2 is not None:\n",
    "         # 1. A must be 0 or 1\n",
    "         model.addConstr(A <= 1)\n",
    "          \n",
    "         # 2. A can only be 1 if B1 is 1\n",
    "         model.addConstr(A <= B1)\n",
    "          \n",
    "         # 3. Create indicator for adjacency\n",
    "         has_adj = model.addVar(vtype=GRB.BINARY, name=f\"{constr_name_base}_HasAdj\")\n",
    "         model.addConstr(sum_expr_S2 <= MAX_ADJACENT_TILES * has_adj)\n",
    "         model.addConstr(has_adj * 0.1 <= sum_expr_S2)\n",
    "          \n",
    "         # 4. A can only be 1 if there's adjacency\n",
    "         model.addConstr(A <= has_adj)\n",
    "          \n",
    "         # 5. A must be 1 if both B1 and has_adj are 1\n",
    "         model.addConstr(A >= B1 + has_adj - 1)\n",
    "\n",
    "     # else:\n",
    "     #      print(f\"Warning: sum_expr_S2 was None for {constr_name_base}. Constraints not added\") # Optional\n",
    "\n",
    "\n",
    "print(f\"Added {constraints_added_count} linking constraints for adjacency.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "6f98060c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating objective function coefficients...\n",
      "Calculating base objective expression...\n",
      "Calculating district adjacency bonus contribution...\n",
      "\n",
      "--- Final Objective Check ---\n",
      "Base Objective Expr Type: <class 'gurobipy._core.LinExpr'>\n",
      "District Adj Bonus Expr Type: <class 'gurobipy._core.LinExpr'>\n",
      "Final Objective Expr Type: <class 'gurobipy._core.LinExpr'>\n",
      "Setting final objective in Gurobi...\n",
      "--- End Final Objective Check ---\n",
      "Gurobi objective function defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Objective Function ---\n",
    "\n",
    "print(\"Calculating objective function coefficients...\")\n",
    "\n",
    "# Calculate base coefficients from Terrain, Features (non-district), CC, River\n",
    "obj_coeffs = {}\n",
    "for coords in tiles_workable:\n",
    "    for d in ALL_DISTRICTS:\n",
    "        # Sum terrain/feature bonuses from adjacent tiles (non-River)\n",
    "        terrain_feature_bonus = 0\n",
    "        for adj_coords in adjacency_map.get(coords, set()):\n",
    "             if adj_coords in features_on_tile:\n",
    "                  for f in features_on_tile.get(adj_coords, set()):\n",
    "                       # Look up bonus value, ensuring f isn't the River key used for edge logic\n",
    "                       if f != RIVER_FEATURE_KEY:\n",
    "                           terrain_feature_bonus += TERRAIN_BONUS_VALUE.get((d, f), 0)\n",
    "\n",
    "        # Add City Center bonus if adjacent\n",
    "        cc_bonus = CC_BONUS_VALUE.get(d, 0) if is_adjacent_to_cc.get(coords, False) else 0\n",
    "\n",
    "        # Add River Adjacency Bonus if *this tile* has a river edge\n",
    "        river_bonus = 0\n",
    "        if has_river_edge.get(coords, False):\n",
    "            river_bonus = TERRAIN_BONUS_VALUE.get((d, RIVER_FEATURE_KEY), 0)\n",
    "\n",
    "        obj_coeffs[coords, d] = terrain_feature_bonus + cc_bonus + river_bonus\n",
    "\n",
    "print(\"Calculating base objective expression...\")\n",
    "# Base objective part from terrain, CC, river bonuses\n",
    "base_objective_expr = quicksum(\n",
    "    build_vars[key] * obj_coeffs.get(key, 0)\n",
    "    for key in build_vars.keys() # Iterate through all defined build variables\n",
    ")\n",
    "\n",
    "print(\"Calculating district adjacency bonus contribution...\")\n",
    "# District adjacency bonus part using the auxiliary variables\n",
    "district_adj_bonus_expr_terms = []\n",
    "processed_obj_keys = set() # Keep track of keys processed in this loop\n",
    "\n",
    "for key, aux_var in adj_district_vars.items():\n",
    "    # Ensure key is the expected tuple format (coords_tuple, d1_string, d2_string)\n",
    "    if not (isinstance(key, tuple) and len(key) == 3):\n",
    "         print(f\"WARNING: Unexpected key format in adj_district_vars: {key}\")\n",
    "         continue\n",
    "    coords_d1, d1, d2 = key # Unpack the key\n",
    "    processed_obj_keys.add(key) # Mark this key as processed\n",
    "\n",
    "    bonus = DISTRICT_PAIR_BONUS.get((d1, d2), 0)\n",
    "    if bonus > 0:\n",
    "        term = aux_var * bonus\n",
    "        district_adj_bonus_expr_terms.append(term)\n",
    "\n",
    "        # --- Add specific debug print for GP bonus ---\n",
    "        if coords_d1 == (51, 16) and d1 == 'Campus' and d2 == 'Government Plaza':\n",
    "            print(f\"\\n*** DEBUG: FOUND AND ADDING objective term for {aux_var.VarName} * {bonus} (GP->Campus Bonus) ***\\n\")\n",
    "        # --- End debug print ---\n",
    "\n",
    "# Check if the specific key we care about was missed in the loop\n",
    "check_key_obj = ((51, 16), 'Campus', 'Government Plaza')\n",
    "if check_key_obj in adj_district_vars and check_key_obj not in processed_obj_keys:\n",
    "     print(f\"*** CRITICAL WARNING: Key {check_key_obj} exists in adj_district_vars but WAS NOT processed in objective loop! ***\")\n",
    "\n",
    "\n",
    "# District base value contribution \n",
    "district_base_value_expr = quicksum(\n",
    "    build_vars[key] * DISTRICT_BASE_VALUE.get(key[1], 0.0)  # key[1] is the district type\n",
    "    for key in build_vars.keys()\n",
    ")\n",
    "\n",
    "district_adj_bonus_expr = quicksum(district_adj_bonus_expr_terms)\n",
    "\n",
    "# --- Final Objective Check & Setting ---\n",
    "print(\"\\n--- Final Objective Check ---\")\n",
    "print(f\"Base Objective Expr Type: {type(base_objective_expr)}\")\n",
    "print(f\"District Adj Bonus Expr Type: {type(district_adj_bonus_expr)}\")\n",
    "\n",
    "# Combine objective parts\n",
    "final_obj = base_objective_expr + district_adj_bonus_expr + district_base_value_expr\n",
    "print(f\"Final Objective Expr Type: {type(final_obj)}\")\n",
    "print(\"Setting final objective in Gurobi...\")\n",
    "model.setObjective(final_obj, GRB.MAXIMIZE)\n",
    "print(\"--- End Final Objective Check ---\")\n",
    "\n",
    "print(\"Gurobi objective function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "id": "6b8251f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining core constraints...\n",
      "Core constraints defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Add Core Constraints ---\n",
    "print(\"Defining core constraints...\")\n",
    "\n",
    "# 1. One District Per Workable Tile\n",
    "for coords in tiles_workable:\n",
    "    model.addConstr(quicksum(build_vars[coords, d] for d in ALL_DISTRICTS if (coords, d) in build_vars) <= 1,\n",
    "                    name=f\"OneDistPerTile_{coords[0]}_{coords[1]}\")\n",
    "\n",
    "# 2. Unique District Limit\n",
    "# Ensure DISTRICTS_UNIQUE has correct, consistent names\n",
    "for d in DISTRICTS_UNIQUE:\n",
    "    # Check if the district 'd' is actually in the list of districts we are considering\n",
    "    if d in ALL_DISTRICTS:\n",
    "         model.addConstr(quicksum(build_vars[coords, d] for coords in tiles_workable if (coords, d) in build_vars) <= 1,\n",
    "                         name=f\"UniqueDistrict_{d}\")\n",
    "    # else:\n",
    "    #      print(f\"Warning: District '{d}' in DISTRICTS_UNIQUE but not in ALL_DISTRICTS. Skipping uniqueness constraint.\")\n",
    "\n",
    "\n",
    "# 3. Mutual Exclusivity\n",
    "# Ensure district names in DISTRICTS_MUTUALLY_EXCLUSIVE are correct\n",
    "for i, me_set in enumerate(DISTRICTS_MUTUALLY_EXCLUSIVE):\n",
    "    valid_me_districts = [d for d in me_set if d in ALL_DISTRICTS] # Filter for districts actually in model\n",
    "    if valid_me_districts:\n",
    "        expr = quicksum(build_vars[coords, d]\n",
    "                        for coords in tiles_workable\n",
    "                        for d in valid_me_districts\n",
    "                        if (coords, d) in build_vars) # Check key exists\n",
    "        model.addConstr(expr <= 1, name=f\"MutExcl_{i}\")\n",
    "\n",
    "print(\"Core constraints defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "1b39a835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining placement constraints...\n",
      "Placement constraints defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Add Specific District Placement Constraints ---\n",
    "print(\"Defining placement constraints...\")\n",
    "\n",
    "# 4. Aqueduct Placement Requirements (Adj to CC & Freshwater)\n",
    "AQUEDUCT = \"Aqueduct\"\n",
    "if AQUEDUCT in ALL_DISTRICTS:\n",
    "    for coords in tiles_workable:\n",
    "        key = (coords, AQUEDUCT)\n",
    "        if key in build_vars: # Check if variable exists\n",
    "            # Force 0 if not adjacent to CC\n",
    "            model.addConstr(build_vars[key] <= (1 if is_adjacent_to_cc.get(coords, False) else 0),\n",
    "                            name=f\"AqueductAdjCC_{coords[0]}_{coords[1]}\")\n",
    "            # Force 0 if not adjacent to Freshwater\n",
    "            model.addConstr(build_vars[key] <= (1 if is_adjacent_to_freshwater.get(coords, False) else 0),\n",
    "                            name=f\"AqueductFreshwater_{coords[0]}_{coords[1]}\")\n",
    "\n",
    "# 5. Harbor Placement Requirements (Coast & Adj to Land)\n",
    "HARBOR = \"Harbor\"\n",
    "if HARBOR in ALL_DISTRICTS:\n",
    "    for coords in tiles_workable:\n",
    "        key = (coords, HARBOR)\n",
    "        if key in build_vars:\n",
    "            # Force 0 if not Coast\n",
    "            model.addConstr(build_vars[key] <= (1 if is_coast.get(coords, False) else 0),\n",
    "                            name=f\"HarborIsCoast_{coords[0]}_{coords[1]}\")\n",
    "            # Force 0 if not adjacent to Land\n",
    "            model.addConstr(build_vars[key] <= (1 if is_adjacent_to_land.get(coords, False) else 0),\n",
    "                            name=f\"HarborAdjLand_{coords[0]}_{coords[1]}\")\n",
    "\n",
    "# 6. Dam Placement Requirements (On Floodplains & On River)\n",
    "DAM = \"Dam\"\n",
    "if DAM in ALL_DISTRICTS:\n",
    "    for coords in tiles_workable:\n",
    "         key = (coords, DAM)\n",
    "         if key in build_vars:\n",
    "              # Force 0 if not on Floodplains tile\n",
    "              model.addConstr(build_vars[key] <= (1 if is_floodplains.get(coords, False) else 0),\n",
    "                              name=f\"DamIsFloodplains_{coords[0]}_{coords[1]}\")\n",
    "              # Force 0 if tile does not have a river edge\n",
    "              model.addConstr(build_vars[key] <= (1 if has_river_edge.get(coords, False) else 0),\n",
    "                              name=f\"DamIsRiver_{coords[0]}_{coords[1]}\")\n",
    "\n",
    "# 7. Only Harbor can be built on coast tiles\n",
    "for coords in tiles_workable:\n",
    "    if is_coast.get(coords, False):  # If this is a coast tile\n",
    "        for d in ALL_DISTRICTS:\n",
    "            if d != \"Harbor\":  # For all non-Harbor districts\n",
    "                key = (coords, d)\n",
    "                if key in build_vars:\n",
    "                    # Prevent non-Harbor districts from being placed on coast\n",
    "                    model.addConstr(build_vars[key] <= 0, \n",
    "                                   name=f\"NoNonHarbor_OnCoast_{coords[0]}_{coords[1]}_{d}\")\n",
    "\n",
    "print(\"Placement constraints defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "4e457515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving the optimization problem using Gurobi...\n",
      "Gurobi Optimizer version 12.0.0 build v12.0.0rc1 (mac64[arm] - Darwin 24.3.0 24D81)\n",
      "\n",
      "CPU model: Apple M2 Max\n",
      "Thread count: 12 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 10004 rows, 3596 columns and 30204 nonzeros\n",
      "Model fingerprint: 0x44256569\n",
      "Variable types: 0 continuous, 3596 integer (3596 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-01, 6e+00]\n",
      "  Objective range  [5e-01, 5e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 7478 rows and 2004 columns\n",
      "Presolve time: 0.10s\n",
      "Presolved: 2526 rows, 1592 columns, 6079 nonzeros\n",
      "Variable types: 0 continuous, 1592 integer (1592 binary)\n",
      "Found heuristic solution: objective 2.0000000\n",
      "\n",
      "Root relaxation: objective 5.327980e+01, 2052 iterations, 0.03 seconds (0.04 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   53.27980    0  636    2.00000   53.27980  2564%     -    0s\n",
      "H    0     0                       6.0000000   53.27980   788%     -    0s\n",
      "H    0     0                      17.0000000   53.27980   213%     -    0s\n",
      "H    0     0                      20.0000000   53.27980   166%     -    0s\n",
      "H    0     0                      22.0000000   53.27980   142%     -    0s\n",
      "H    0     0                      26.0000000   53.27980   105%     -    0s\n",
      "H    0     0                      29.0000000   53.27980  83.7%     -    0s\n",
      "H    0     0                      29.5000000   53.27980  80.6%     -    0s\n",
      "H    0     0                      31.0000000   53.27980  71.9%     -    0s\n",
      "H    0     0                      31.5000000   53.27980  69.1%     -    0s\n",
      "     0     0   51.17317    0  863   31.50000   51.17317  62.5%     -    0s\n",
      "H    0     0                      33.0000000   51.17317  55.1%     -    0s\n",
      "H    0     0                      34.0000000   51.17317  50.5%     -    0s\n",
      "H    0     0                      37.5000000   51.15275  36.4%     -    0s\n",
      "     0     0   51.15275    0  837   37.50000   51.15275  36.4%     -    0s\n",
      "     0     0   51.14961    0  850   37.50000   51.14961  36.4%     -    0s\n",
      "     0     0   51.14941    0  871   37.50000   51.14941  36.4%     -    0s\n",
      "H    0     0                      38.0000000   48.93778  28.8%     -    0s\n",
      "     0     0   48.93778    0  745   38.00000   48.93778  28.8%     -    0s\n",
      "H    0     0                      39.0000000   48.93778  25.5%     -    0s\n",
      "H    0     0                      40.0000000   48.93778  22.3%     -    0s\n",
      "     0     0   48.49540    0  901   40.00000   48.49540  21.2%     -    0s\n",
      "     0     0   48.42786    0  882   40.00000   48.42786  21.1%     -    0s\n",
      "     0     0   48.39863    0  951   40.00000   48.39863  21.0%     -    0s\n",
      "     0     0   47.89560    0  633   40.00000   47.89560  19.7%     -    0s\n",
      "     0     0   47.83216    0  636   40.00000   47.83216  19.6%     -    0s\n",
      "     0     0   47.79664    0  661   40.00000   47.79664  19.5%     -    0s\n",
      "     0     0   47.79148    0  662   40.00000   47.79148  19.5%     -    0s\n",
      "     0     0   47.79108    0  658   40.00000   47.79108  19.5%     -    0s\n",
      "     0     0   47.77001    0  644   40.00000   47.77001  19.4%     -    0s\n",
      "     0     0   47.74838    0  589   40.00000   47.74838  19.4%     -    0s\n",
      "     0     0   47.74099    0  632   40.00000   47.74099  19.4%     -    0s\n",
      "     0     0   47.73831    0  635   40.00000   47.73831  19.3%     -    0s\n",
      "     0     0   47.73719    0  645   40.00000   47.73719  19.3%     -    0s\n",
      "     0     0   47.73672    0  633   40.00000   47.73672  19.3%     -    0s\n",
      "     0     0   47.73661    0  632   40.00000   47.73661  19.3%     -    0s\n",
      "     0     0   47.73629    0  640   40.00000   47.73629  19.3%     -    0s\n",
      "H    0     0                      40.5000000   47.73629  17.9%     -    1s\n",
      "     0     0   47.73627    0  643   40.50000   47.73627  17.9%     -    1s\n",
      "     0     0   47.73627    0  638   40.50000   47.73627  17.9%     -    1s\n",
      "     0     2   47.73583    0  638   40.50000   47.73583  17.9%     -    1s\n",
      "\n",
      "Cutting planes:\n",
      "  Zero half: 9\n",
      "  RLT: 170\n",
      "  BQP: 242\n",
      "\n",
      "Explored 813 nodes (118926 simplex iterations) in 3.04 seconds (4.22 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 10: 40.5 40 39 ... 29.5\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 4.050000000000e+01, best bound 4.050000000000e+01, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "# --- Solve the Optimization Problem ---\n",
    "print(\"Solving the optimization problem using Gurobi...\")\n",
    "# Optional: Write model to file for debugging\n",
    "# model.write(\"civ6_model_debug.lp\")\n",
    "# print(\"Model written to civ6_model_debug.lp\")\n",
    "\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "c62a3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gurobi Optimization Results ---\n",
      "Status: Optimal\n",
      "Optimal Total Adjacency Score = 40.50\n",
      "\n",
      "Optimal District Placements:\n",
      "  Build Aqueduct at (57, 25)\n",
      "  Build Campus at (55, 27)\n",
      "  Build Canal at (56, 26)\n",
      "  Build Commercial Hub at (58, 26)\n",
      "  Build Dam at (58, 27)\n",
      "  Build Entertainment Complex at (56, 27)\n",
      "  Build Government Plaza at (58, 25)\n",
      "  Build Harbor at (59, 25)\n",
      "  Build Holy Site at (54, 26)\n",
      "  Build Industrial Zone at (57, 26)\n",
      "  Build Theater Square at (55, 26)\n",
      "--- End Results ---\n"
     ]
    }
   ],
   "source": [
    "# --- Print the Optimization Results ---\n",
    "print(\"\\n--- Gurobi Optimization Results ---\")\n",
    "\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    print(f\"Status: Optimal\")\n",
    "    print(f\"Optimal Total Adjacency Score = {model.ObjVal:.2f}\")\n",
    "    print(\"\\nOptimal District Placements:\")\n",
    "    placed_districts = 0\n",
    "    solution_placements = []\n",
    "    # Iterate through build_vars dictionary\n",
    "    for key, var in build_vars.items():\n",
    "         # Use a tolerance for checking binary variable solution\n",
    "         if var.X > 0.5:\n",
    "              coords, district_name = key\n",
    "              solution_placements.append((district_name, coords[0], coords[1]))\n",
    "              placed_districts += 1\n",
    "\n",
    "    # Sort placements for readability (by district name, then coords)\n",
    "    solution_placements.sort()\n",
    "    for placement in solution_placements:\n",
    "        print(f\"  Build {placement[0]} at ({placement[1]}, {placement[2]})\")\n",
    "\n",
    "    if placed_districts == 0:\n",
    "        print(\"  No districts were placed in the optimal solution.\")\n",
    "\n",
    "# --- Modify this block within Cell 15 ---\n",
    "\n",
    "# --- Modify this block within Cell 15 AGAIN ---\n",
    "\n",
    "elif model.Status == GRB.INFEASIBLE:\n",
    "    print(\"Status: Infeasible - The problem has no solution.\")\n",
    "    print(\"Check constraints, data (especially workable tiles), and bonus values.\")\n",
    "    # Compute and print IIS (Irreducible Inconsistent Subsystem) to help debug\n",
    "    print(\"\\nComputing IIS to identify conflicting constraints...\")\n",
    "    try:\n",
    "        model.computeIIS() # Compute the IIS first\n",
    "        model.update() # Ensure model state is updated after IIS computation\n",
    "\n",
    "        # --- Get constraints using indices from IIS results ---\n",
    "        print(\"Conflicting Constraints:\")\n",
    "        if hasattr(model, 'IISConstr'):\n",
    "            # Get the list of all linear constraints in the model\n",
    "            all_constrs = model.getConstrs()\n",
    "            # IISConstr likely contains indices into this list\n",
    "            iis_constr_indices = model.IISConstr\n",
    "            if not iis_constr_indices:\n",
    "                 print(\"  No conflicting constraints found in IISConstr list.\")\n",
    "            else:\n",
    "                 for index in iis_constr_indices:\n",
    "                      try:\n",
    "                           # Use the index to get the actual constraint object\n",
    "                           constraint = all_constrs[index]\n",
    "                           print(f\"  {constraint.ConstrName}\")\n",
    "                      except IndexError:\n",
    "                           print(f\"  Error: Invalid constraint index {index} found in IISConstr.\")\n",
    "                      except AttributeError:\n",
    "                           print(f\"  Error: Object at index {index} has no ConstrName.\")\n",
    "        else:\n",
    "             print(\"  Could not retrieve IIS Constraints (model.IISConstr attribute missing).\")\n",
    "\n",
    "\n",
    "        # --- Get variable bounds using indices from IIS results ---\n",
    "        print(\"Conflicting Variable Bounds:\")\n",
    "        lb_conflict = False\n",
    "        ub_conflict = False\n",
    "        if hasattr(model, 'IISLB') or hasattr(model, 'IISUB'):\n",
    "             # Get the list of all variables in the model\n",
    "             all_vars = model.getVars()\n",
    "\n",
    "             if hasattr(model, 'IISLB'):\n",
    "                  iis_lb_indices = model.IISLB\n",
    "                  if iis_lb_indices:\n",
    "                       lb_conflict = True\n",
    "                       for index in iis_lb_indices:\n",
    "                            try:\n",
    "                                 variable = all_vars[index]\n",
    "                                 print(f\"  {variable.VarName} (Lower Bound)\")\n",
    "                            except IndexError:\n",
    "                                 print(f\"  Error: Invalid variable index {index} found in IISLB.\")\n",
    "                            except AttributeError:\n",
    "                                 print(f\"  Error: Object at index {index} has no VarName.\")\n",
    "                  # else: print(\"  No conflicting lower bounds found.\") # Optional message\n",
    "\n",
    "             if hasattr(model, 'IISUB'):\n",
    "                  iis_ub_indices = model.IISUB\n",
    "                  if iis_ub_indices:\n",
    "                       ub_conflict = True\n",
    "                       for index in iis_ub_indices:\n",
    "                            try:\n",
    "                                 variable = all_vars[index]\n",
    "                                 print(f\"  {variable.VarName} (Upper Bound)\")\n",
    "                            except IndexError:\n",
    "                                 print(f\"  Error: Invalid variable index {index} found in IISUB.\")\n",
    "                            except AttributeError:\n",
    "                                 print(f\"  Error: Object at index {index} has no VarName.\")\n",
    "                  # else: print(\"  No conflicting upper bounds found.\") # Optional message\n",
    "\n",
    "        if not lb_conflict and not ub_conflict:\n",
    "             print(\"  No conflicting variable bounds found in IIS lists.\")\n",
    "\n",
    "\n",
    "        # Optional: Write IIS to a file for detailed analysis\n",
    "        # model.write(\"civ6_infeasible.ilp\")\n",
    "        # print(\"IIS written to civ6_infeasible.ilp\")\n",
    "\n",
    "    except GurobiError as iis_error:\n",
    "        print(f\"Could not compute IIS or get constraints/variables: {iis_error}\")\n",
    "    except AttributeError as attr_error:\n",
    "         # Catch potential lingering issues or version differences\n",
    "         print(f\"Attribute Error during IIS processing (check Gurobi version/API): {attr_error}\")\n",
    "    except Exception as e:\n",
    "         print(f\"An error occurred during IIS computation: {e}\")\n",
    "\n",
    "# --- End modification ---\n",
    "\n",
    "\n",
    "elif model.Status == GRB.UNBOUNDED:\n",
    "    print(\"Status: Unbounded - The objective can be increased indefinitely.\")\n",
    "    print(\"This usually indicates missing constraints or an error in the objective function/coefficients.\")\n",
    "else:\n",
    "    # Consult Gurobi documentation for other status codes\n",
    "    print(f\"Status Code: {model.Status} (Not Optimal/Infeasible/Unbounded)\")\n",
    "    print(\"Solver did not find an optimal solution. Check Gurobi logs or status code meaning.\")\n",
    "\n",
    "print(\"--- End Results ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "402eac4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District Base Value Contribution: 15.00\n",
      "District-to-district adjacency contributions:\n",
      "  Commercial Hub at (58, 26) gets +2 from adjacent Harbor\n",
      "  Theater Square at (55, 26) gets +1 from adjacent Entertainment Complex\n",
      "  Industrial Zone at (57, 26) gets +2 from adjacent Aqueduct\n",
      "  Industrial Zone at (57, 26) gets +2 from adjacent Dam\n",
      "  Industrial Zone at (57, 26) gets +2 from adjacent Canal\n",
      "  Harbor at (59, 25) gets +1 from adjacent Government Plaza\n",
      "  Commercial Hub at (58, 26) gets +1 from adjacent Government Plaza\n",
      "  Industrial Zone at (57, 26) gets +1 from adjacent Government Plaza\n",
      "  Campus at (55, 27) gets +0.5 from adjacent Holy Site\n",
      "  Campus at (55, 27) gets +0.5 from adjacent Theater Square\n",
      "  Campus at (55, 27) gets +0.5 from adjacent Entertainment Complex\n",
      "  Holy Site at (54, 26) gets +0.5 from adjacent Campus\n",
      "  Holy Site at (54, 26) gets +0.5 from adjacent Theater Square\n",
      "  Theater Square at (55, 26) gets +0.5 from adjacent Campus\n",
      "  Theater Square at (55, 26) gets +0.5 from adjacent Holy Site\n",
      "  Theater Square at (55, 26) gets +0.5 from adjacent Canal\n",
      "  Industrial Zone at (57, 26) gets +0.5 from adjacent Commercial Hub\n",
      "  Commercial Hub at (58, 26) gets +0.5 from adjacent Industrial Zone\n",
      "  Commercial Hub at (58, 26) gets +0.5 from adjacent Dam\n",
      "\n",
      "--- Debugging GP Adjacency to Optimal Campus at (55, 27) ---\n",
      "Tiles adjacent to Campus (55, 27): {(56, 27), (54, 26), (54, 28), (55, 26), (54, 27), (55, 28)}\n",
      "WORKABLE tiles adjacent to Campus: {(56, 27), (54, 26), (55, 26)}\n",
      "\n",
      "INFO: There ARE workable tiles adjacent to the Campus where GP could potentially be placed.\n",
      "  GP build variables exist for adjacent workable tiles: 3 found.\n",
      "Auxiliary variable for Campus <- GP bonus exists: AdjDist_55_27_Campus_from_Government Plaza\n",
      "Bonus value ('Campus', 'Government Plaza') read from dict: 1\n",
      "  Value of Aux Var in solution: -0\n",
      "--- End GP Debug ---\n"
     ]
    }
   ],
   "source": [
    "# --- Debugging Checks (Run After Printing Results) ---\n",
    "\n",
    "# print contribution of district base value to objective\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    district_base_value = sum(DISTRICT_BASE_VALUE.get(key[1], 0) * var.X \n",
    "                             for key, var in build_vars.items() if var.X > 0.5)\n",
    "    print(f\"District Base Value Contribution: {district_base_value:.2f}\")\n",
    "\n",
    "# Add after solving to check why GP isn't placed\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    print(\"District-to-district adjacency contributions:\")\n",
    "    for key, var in adj_district_vars.items():\n",
    "        if var.X > 0.5:\n",
    "            coords, d1, d2 = key\n",
    "            bonus = DISTRICT_PAIR_BONUS.get((d1, d2), 0)\n",
    "            print(f\"  {d1} at {coords} gets +{bonus} from adjacent {d2}\")\n",
    "        else:\n",
    "            # print(f\"  {key} not placed in solution (var.X = {var.X:.2f})\")\n",
    "            pass\n",
    "\n",
    "# Find optimal campus location if one was placed\n",
    "optimal_campus_loc = None\n",
    "if model.Status == GRB.OPTIMAL:\n",
    "    for key, var in build_vars.items():\n",
    "        if var.X > 0.5 and key[1] == 'Campus':\n",
    "            optimal_campus_loc = key[0]\n",
    "            break # Assume only one campus\n",
    "\n",
    "if optimal_campus_loc:\n",
    "    print(f\"\\n--- Debugging GP Adjacency to Optimal Campus at {optimal_campus_loc} ---\")\n",
    "\n",
    "    # Check if the optimal location is in the adjacency map\n",
    "    if optimal_campus_loc not in adjacency_map:\n",
    "        print(f\"ERROR: Optimal Campus location {optimal_campus_loc} not found in adjacency_map keys!\")\n",
    "    else:\n",
    "        adj_to_campus = adjacency_map[optimal_campus_loc]\n",
    "        print(f\"Tiles adjacent to Campus {optimal_campus_loc}: {adj_to_campus}\")\n",
    "\n",
    "        # Find which of these adjacent tiles are actually workable\n",
    "        workable_adj_to_campus = adj_to_campus.intersection(tiles_workable)\n",
    "        print(f\"WORKABLE tiles adjacent to Campus: {workable_adj_to_campus}\")\n",
    "\n",
    "        if not workable_adj_to_campus:\n",
    "            print(\"\\nCONCLUSION: There are NO workable tiles adjacent to the optimal Campus location.\")\n",
    "            print(\"The Government Plaza cannot be placed adjacent to the Campus, so its bonus cannot be achieved.\")\n",
    "        else:\n",
    "            print(\"\\nINFO: There ARE workable tiles adjacent to the Campus where GP could potentially be placed.\")\n",
    "            # Further check if GP build vars exist for these specific tiles\n",
    "            gp_build_vars_on_adj = []\n",
    "            for adj_coords in workable_adj_to_campus:\n",
    "                 gp_key = (adj_coords, 'Government Plaza')\n",
    "                 if gp_key in build_vars:\n",
    "                      gp_build_vars_on_adj.append(build_vars[gp_key].VarName)\n",
    "                 else:\n",
    "                      print(f\"  WARNING: Build variable for GP not found for workable adjacent tile {adj_coords}!\")\n",
    "            if gp_build_vars_on_adj:\n",
    "                 print(f\"  GP build variables exist for adjacent workable tiles: {len(gp_build_vars_on_adj)} found.\")\n",
    "\n",
    "    # Verify the specific auxiliary variable exists and the bonus value is read correctly\n",
    "    adj_var_key = (optimal_campus_loc, 'Campus', 'Government Plaza')\n",
    "    if adj_var_key in adj_district_vars:\n",
    "         print(f\"Auxiliary variable for Campus <- GP bonus exists: {adj_district_vars[adj_var_key].VarName}\")\n",
    "         # Use the *actual* dictionary value used in the objective calculation\n",
    "         bonus_val = DISTRICT_PAIR_BONUS.get(('Campus', 'Government Plaza'), -999) # Use -999 to show if key missing\n",
    "         print(f\"Bonus value ('Campus', 'Government Plaza') read from dict: {bonus_val}\")\n",
    "         # Check if the variable was active in the solution (if GP bonus was expected)\n",
    "         if model.Status == GRB.OPTIMAL:\n",
    "             print(f\"  Value of Aux Var in solution: {adj_district_vars[adj_var_key].X:.0f}\")\n",
    "\n",
    "    else:\n",
    "         print(f\"ERROR: Auxiliary variable {adj_var_key} DOES NOT exist. Check its creation loop.\")\n",
    "\n",
    "    print(\"--- End GP Debug ---\")\n",
    "elif model.Status == GRB.OPTIMAL:\n",
    "    print(\"\\n--- GP Debug Skipped: No Campus placed in optimal solution. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "7d1b4c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated JSON: 12 tiles with recommended_district\n"
     ]
    }
   ],
   "source": [
    "def update_json_with_district_recommendations(build_vars, city_center_coords, \n",
    "                                             data_file='civ_map_data.json',\n",
    "                                             scenario_name=None):\n",
    "    # Load existing data\n",
    "    with open(data_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Track which tiles received district recommendations\n",
    "    tiles_with_districts = {}\n",
    "    \n",
    "    # Add city center to the recommendations\n",
    "    x_cc, y_cc = city_center_coords\n",
    "    cc_key = f\"{x_cc},{y_cc}\"\n",
    "    tiles_with_districts[cc_key] = \"citycenter\"\n",
    "    \n",
    "    # Extract district placements from optimization results\n",
    "    for (coords, district_type), var in build_vars.items():\n",
    "        if var.X > 0.5:\n",
    "            x, y = coords\n",
    "            key = f\"{x},{y}\"\n",
    "            formatted_district = district_type.lower().replace(' ', '')\n",
    "            tiles_with_districts[key] = formatted_district\n",
    "    \n",
    "    # Determine field name based on scenario\n",
    "    field_name = 'recommended_district'\n",
    "    if scenario_name:\n",
    "        field_name = f'scenario_{scenario_name}'\n",
    "    \n",
    "    # Update tiles\n",
    "    recommended_count = 0\n",
    "    \n",
    "    for tile in data['tiles']:\n",
    "        key = f\"{tile['x']},{tile['y']}\"\n",
    "        \n",
    "        # Clear previous data for this specific scenario\n",
    "        if field_name in tile:\n",
    "            del tile[field_name]\n",
    "            \n",
    "        # Add new recommendation if this tile has one\n",
    "        if key in tiles_with_districts:\n",
    "            tile[field_name] = tiles_with_districts[key]\n",
    "            recommended_count += 1\n",
    "    \n",
    "    # Write the updated data back\n",
    "    with open(data_file, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"Updated JSON: {recommended_count} tiles with {field_name}\")\n",
    "\n",
    "update_json_with_district_recommendations(build_vars, (cc_x, cc_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "id": "3b357574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR SENSITVITY ANALYSIS\n",
    "def run_district_optimization(\n",
    "    pre_calc_data,  # This will be the dictionary returned by perform_pre_calculations\n",
    "    all_districts_list,\n",
    "    district_pair_bonus_dict,\n",
    "    features_dict, # For auxiliary variable creation\n",
    "    district_base_value_dict_global, # The global one that might be temporarily overridden\n",
    "    cc_bonus_value_dict,\n",
    "    terrain_bonus_value_dict,\n",
    "    river_feature_key_str,\n",
    "    districts_unique_list,\n",
    "    districts_mutually_exclusive_list,\n",
    "    max_adjacent_tiles_const,\n",
    "    district_values_override=None, # Renamed from district_values to avoid conflict\n",
    "    scenario_name=None\n",
    "):\n",
    "    \"\"\"Run the optimization with custom district values and pre-calculated data.\n",
    "    \"\"\"\n",
    "    global DISTRICT_BASE_VALUE # Still need this if district_values_override modifies it.\n",
    "\n",
    "    # Extract pre-calculated data for easier access\n",
    "    # These will shadow the global variables for the scope of this function call\n",
    "    city_center_coords = pre_calc_data[\"city_center_coords\"] # For update_json\n",
    "    tiles_workable = pre_calc_data[\"tiles_workable\"]\n",
    "    adjacency_map = pre_calc_data[\"adjacency_map\"]\n",
    "    features_on_tile = pre_calc_data[\"features_on_tile\"]\n",
    "    has_river_edge = pre_calc_data[\"has_river_edge\"]\n",
    "    is_adjacent_to_cc = pre_calc_data[\"is_adjacent_to_cc\"]\n",
    "    is_adjacent_to_freshwater = pre_calc_data[\"is_adjacent_to_freshwater\"]\n",
    "    is_coast = pre_calc_data[\"is_coast\"]\n",
    "    is_adjacent_to_land = pre_calc_data[\"is_adjacent_to_land\"]\n",
    "    is_floodplains = pre_calc_data[\"is_floodplains\"]\n",
    "    # Note: ALL_DISTRICTS, DISTRICT_PAIR_BONUS, FEATURES, etc. are passed or reconstructed\n",
    "\n",
    "    # Save original global DISTRICT_BASE_VALUE to restore later\n",
    "    original_global_district_base_values = district_base_value_dict_global.copy()\n",
    "    current_district_base_value = district_base_value_dict_global.copy() # Work with a copy\n",
    "\n",
    "    try:\n",
    "        # Use provided override values if available\n",
    "        if district_values_override:\n",
    "            for district, value in district_values_override.items():\n",
    "                current_district_base_value[district] = value\n",
    "        # --- Initialize model ---\n",
    "        model = Model(f\"Civ6_DistOpt_{scenario_name if scenario_name else 'default'}\")\n",
    "        model.setParam('OutputFlag', 0)  # Suppress output\n",
    "\n",
    "        # --- Define Main Decision Variables: Build(x, y, d) ---\n",
    "        build_vars = {}\n",
    "        # print(\"Creating main 'Build' variables...\") # Consider removing prints for batch runs\n",
    "        for coords in tiles_workable: # Uses local tiles_workable\n",
    "            for d in all_districts_list: # Uses passed all_districts_list\n",
    "                var_name = f\"Build[{coords[0]},{coords[1]},{d}]\"\n",
    "                build_vars[coords, d] = model.addVar(vtype=GRB.BINARY, name=var_name)\n",
    "        model.update()\n",
    "        # print(f\"Gurobi 'Build' variables defined ({len(build_vars)} variables).\")\n",
    "\n",
    "        # --- Define Auxiliary Variables for District Adjacency ---\n",
    "        adj_district_vars = {}\n",
    "        # print(\"Defining auxiliary adjacency variables...\")\n",
    "        for (d1, d2), bonus_value in district_pair_bonus_dict.items(): # uses passed\n",
    "            if bonus_value > 0:\n",
    "                for coords_d1 in tiles_workable: # uses local\n",
    "                    if (coords_d1, d1) in build_vars:\n",
    "                         current_key = (coords_d1, d1, d2)\n",
    "                         adj_district_vars[current_key] = model.addVar(vtype=GRB.BINARY, name=f\"AdjDist_{coords_d1[0]}_{coords_d1[1]}_{d1}_from_{d2}\")\n",
    "        model.update()\n",
    "        # print(f\"Defined {len(adj_district_vars)} auxiliary adjacency variables.\")\n",
    "\n",
    "        # --- Add Linking Constraints for Auxiliary Adjacency Variables ---\n",
    "        # print(\"Adding linking constraints for adjacency variables...\")\n",
    "        for (coords_d1, d1, d2), A in adj_district_vars.items():\n",
    "            B1 = build_vars[coords_d1, d1]\n",
    "            _adjacent_tiles = adjacency_map.get(coords_d1, set()) # uses local\n",
    "            sum_expr_S2 = None\n",
    "            if d2 in all_districts_list: # uses passed\n",
    "                 s2_terms = [build_vars.get((adj_coords, d2), 0)\n",
    "                             for adj_coords in _adjacent_tiles\n",
    "                             if adj_coords in tiles_workable and (adj_coords, d2) in build_vars] # uses local\n",
    "                 sum_expr_S2 = quicksum(s2_terms)\n",
    "            elif d2 in features_dict: # uses passed features_dict\n",
    "                 sum_expr_S2 = quicksum(1\n",
    "                                        for adj_coords in _adjacent_tiles\n",
    "                                        if adj_coords in features_on_tile and d2 in features_on_tile[adj_coords]) # uses local\n",
    "            else: continue\n",
    "            if sum_expr_S2 is not None:\n",
    "                 model.addConstr(A <= 1)\n",
    "                 model.addConstr(A <= B1)\n",
    "                 has_adj = model.addVar(vtype=GRB.BINARY, name=f\"LinkAdj_{coords_d1[0]}_{coords_d1[1]}_{d1}_{d2}_HasAdj\")\n",
    "                 model.addConstr(sum_expr_S2 <= max_adjacent_tiles_const * has_adj) # uses passed\n",
    "                 model.addConstr(has_adj * 0.1 <= sum_expr_S2)\n",
    "                 model.addConstr(A <= has_adj)\n",
    "                 model.addConstr(A >= B1 + has_adj - 1)\n",
    "        # print(f\"Added linking constraints for adjacency.\")\n",
    "\n",
    "\n",
    "        # --- Define Objective Function ---\n",
    "        # print(\"Calculating objective function coefficients...\")\n",
    "        obj_coeffs = {}\n",
    "        for coords in tiles_workable: # uses local\n",
    "            for d in all_districts_list: # uses passed\n",
    "                terrain_feature_bonus = 0\n",
    "                for adj_coords in adjacency_map.get(coords, set()): # uses local\n",
    "                     if adj_coords in features_on_tile: # uses local\n",
    "                          for f_feature in features_on_tile.get(adj_coords, set()): # uses local\n",
    "                               if f_feature != river_feature_key_str: # uses passed\n",
    "                                   terrain_feature_bonus += terrain_bonus_value_dict.get((d, f_feature), 0) # uses passed\n",
    "                _cc_bonus = cc_bonus_value_dict.get(d, 0) if is_adjacent_to_cc.get(coords, False) else 0 # uses local is_adjacent_to_cc\n",
    "                _river_bonus = 0\n",
    "                if has_river_edge.get(coords, False): # uses local\n",
    "                    _river_bonus = terrain_bonus_value_dict.get((d, river_feature_key_str), 0) # uses passed\n",
    "                obj_coeffs[coords, d] = terrain_feature_bonus + _cc_bonus + _river_bonus\n",
    "\n",
    "        base_objective_expr = quicksum(build_vars[key] * obj_coeffs.get(key, 0) for key in build_vars.keys())\n",
    "        district_adj_bonus_expr_terms = []\n",
    "        for key_aux, aux_var in adj_district_vars.items():\n",
    "            coords_d1_obj, d1_obj, d2_obj = key_aux\n",
    "            bonus_obj = district_pair_bonus_dict.get((d1_obj, d2_obj), 0) # uses passed\n",
    "            if bonus_obj > 0:\n",
    "                district_adj_bonus_expr_terms.append(aux_var * bonus_obj)\n",
    "\n",
    "        # Use current_district_base_value for this run\n",
    "        district_base_value_expr = quicksum(\n",
    "            build_vars[key] * current_district_base_value.get(key[1], 0.0)\n",
    "            for key in build_vars.keys()\n",
    "        )\n",
    "        district_adj_bonus_expr = quicksum(district_adj_bonus_expr_terms)\n",
    "        final_obj = base_objective_expr + district_adj_bonus_expr + district_base_value_expr\n",
    "        model.setObjective(final_obj, GRB.MAXIMIZE)\n",
    "        # print(\"Gurobi objective function defined.\")\n",
    "\n",
    "\n",
    "        # --- Add Core Constraints ---\n",
    "        # print(\"Defining core constraints...\")\n",
    "        for coords in tiles_workable: # uses local\n",
    "            model.addConstr(quicksum(build_vars[coords, d_constr] for d_constr in all_districts_list if (coords, d_constr) in build_vars) <= 1, name=f\"OneDistPerTile_{coords[0]}_{coords[1]}\")\n",
    "        for d_unique in districts_unique_list: # uses passed\n",
    "            if d_unique in all_districts_list:\n",
    "                 model.addConstr(quicksum(build_vars[coords_constr, d_unique] for coords_constr in tiles_workable if (coords_constr, d_unique) in build_vars) <= 1, name=f\"UniqueDistrict_{d_unique}\")\n",
    "        for i_me, me_set in enumerate(districts_mutually_exclusive_list): # uses passed\n",
    "            valid_me_districts = [d_me for d_me in me_set if d_me in all_districts_list]\n",
    "            if valid_me_districts:\n",
    "                expr = quicksum(build_vars[coords_me, d_me_constr] for coords_me in tiles_workable for d_me_constr in valid_me_districts if (coords_me, d_me_constr) in build_vars)\n",
    "                model.addConstr(expr <= 1, name=f\"MutExcl_{i_me}\")\n",
    "        # print(\"Core constraints defined.\")\n",
    "\n",
    "        # --- Add Specific District Placement Constraints ---\n",
    "        # print(\"Defining placement constraints...\")\n",
    "        AQUEDUCT = \"Aqueduct\"\n",
    "        if AQUEDUCT in all_districts_list:\n",
    "            for coords in tiles_workable:\n",
    "                key_aq = (coords, AQUEDUCT)\n",
    "                if key_aq in build_vars:\n",
    "                    model.addConstr(build_vars[key_aq] <= (1 if is_adjacent_to_cc.get(coords, False) else 0), name=f\"AqueductAdjCC_{coords[0]}_{coords[1]}\") # local\n",
    "                    model.addConstr(build_vars[key_aq] <= (1 if is_adjacent_to_freshwater.get(coords, False) else 0), name=f\"AqueductFreshwater_{coords[0]}_{coords[1]}\") # local\n",
    "        HARBOR = \"Harbor\"\n",
    "        if HARBOR in all_districts_list:\n",
    "            for coords in tiles_workable:\n",
    "                key_ha = (coords, HARBOR)\n",
    "                if key_ha in build_vars:\n",
    "                    model.addConstr(build_vars[key_ha] <= (1 if is_coast.get(coords, False) else 0), name=f\"HarborIsCoast_{coords[0]}_{coords[1]}\") # local\n",
    "                    model.addConstr(build_vars[key_ha] <= (1 if is_adjacent_to_land.get(coords, False) else 0), name=f\"HarborAdjLand_{coords[0]}_{coords[1]}\") # local\n",
    "        DAM = \"Dam\"\n",
    "        if DAM in all_districts_list:\n",
    "            for coords in tiles_workable:\n",
    "                 key_da = (coords, DAM)\n",
    "                 if key_da in build_vars:\n",
    "                      model.addConstr(build_vars[key_da] <= (1 if is_floodplains.get(coords, False) else 0), name=f\"DamIsFloodplains_{coords[0]}_{coords[1]}\") # local\n",
    "                      model.addConstr(build_vars[key_da] <= (1 if has_river_edge.get(coords, False) else 0), name=f\"DamIsRiver_{coords[0]}_{coords[1]}\") # local\n",
    "        for coords in tiles_workable: # local\n",
    "            if is_coast.get(coords, False): # local\n",
    "                for d_coast_constr in all_districts_list:\n",
    "                    if d_coast_constr != HARBOR:\n",
    "                        key_coast = (coords, d_coast_constr)\n",
    "                        if key_coast in build_vars:\n",
    "                            model.addConstr(build_vars[key_coast] <= 0, name=f\"NoNonHarbor_OnCoast_{coords[0]}_{coords[1]}_{d_coast_constr}\")\n",
    "        # print(\"Placement constraints defined.\")\n",
    "\n",
    "        # Run optimization\n",
    "        model.optimize()\n",
    "        results = {\n",
    "            \"objective_value\": model.ObjVal if model.Status == GRB.OPTIMAL else None,\n",
    "            \"status\": model.Status,\n",
    "            \"district_placements\": [],\n",
    "            \"scenario\": scenario_name,\n",
    "            \"city_center\": city_center_coords # Store the CC for this run\n",
    "        }\n",
    "        if model.Status == GRB.OPTIMAL:\n",
    "            for key_res, var_res in build_vars.items():\n",
    "                if var_res.X > 0.5:\n",
    "                    coords_res, district_name_res = key_res\n",
    "                    results[\"district_placements\"].append((district_name_res, coords_res))\n",
    "            update_json_with_district_recommendations(\n",
    "                build_vars,\n",
    "                city_center_coords, # Uses local (passed via pre_calc_data)\n",
    "                scenario_name=scenario_name # This will be like \"start_56_25\"\n",
    "            )\n",
    "        return model, build_vars, results\n",
    "    finally:\n",
    "        # Restore original global DISTRICT_BASE_VALUE\n",
    "        DISTRICT_BASE_VALUE = original_global_district_base_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "51e66273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_yield_sensitivity_analysis(yields_to_analyze=None, boost_factors=None):\n",
    "    \"\"\"Run optimization for different yield priorities\n",
    "    \n",
    "    Args:\n",
    "        yields_to_analyze: List of yields to prioritize\n",
    "        boost_factors: List of boost factors to try for each yield\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of results by yield and boost factor\n",
    "    \"\"\"\n",
    "    if yields_to_analyze is None:\n",
    "        yields_to_analyze = [\"science\", \"culture\", \"production\", \"gold\", \"faith\"]\n",
    "    \n",
    "    if boost_factors is None:\n",
    "        boost_factors = [1.5, 2.0, 3.0]\n",
    "        \n",
    "    # Also run a balanced scenario\n",
    "    results = {\n",
    "        \"balanced\": {}\n",
    "    }\n",
    "    \n",
    "    # Run balanced scenario first\n",
    "    print(f\"Running balanced scenario...\")\n",
    "    _, _, balanced_result = run_district_optimization(\n",
    "        district_values=DISTRICT_BASE_VALUE,\n",
    "        scenario_name=\"balanced\"\n",
    "    )\n",
    "    results[\"balanced\"] = balanced_result\n",
    "    \n",
    "    # Run scenarios for each yield and boost factor\n",
    "    for yield_type in yields_to_analyze:\n",
    "        results[yield_type] = {}\n",
    "        \n",
    "        for boost in boost_factors:\n",
    "            scenario_name = f\"{yield_type}_{boost}\"\n",
    "            print(f\"Running {scenario_name} scenario...\")\n",
    "            \n",
    "            # Create priority profile\n",
    "            priority_profile = create_priority_profile(yield_type, boost)\n",
    "            \n",
    "            # Run optimization with these priorities\n",
    "            _, _, scenario_result = run_district_optimization(\n",
    "                district_values=priority_profile,\n",
    "                scenario_name=scenario_name\n",
    "            )\n",
    "            \n",
    "            # Store results\n",
    "            results[yield_type][boost] = scenario_result\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "3da273a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function for LOCATION Sensitivity Analysis ---\n",
    "\n",
    "def run_location_sensitivity_analysis(top_n_potential_cc, df_map_data,\n",
    "                                      # Args for pre_calculations\n",
    "                                      radius_const, all_districts_const, features_const,\n",
    "                                      impassable_terrain_const, impassable_features_const, river_feature_key_const,\n",
    "                                      # Args for run_district_optimization\n",
    "                                      district_pair_bonus_const, district_base_value_const,\n",
    "                                      cc_bonus_value_const, terrain_bonus_value_const,\n",
    "                                      districts_unique_const, districts_mutually_exclusive_const,\n",
    "                                      max_adj_tiles_const,\n",
    "                                      # Optional: district value overrides for all runs in this analysis\n",
    "                                      district_values_override_all=None\n",
    "                                     ):\n",
    "    \"\"\"\n",
    "    Runs the district optimization for several potential city center locations.\n",
    "    \"\"\"\n",
    "    location_results = {} # Store results, keyed by \"start_x_y\"\n",
    "\n",
    "    # These are the global constants defined in Cell 3 that perform_pre_calculations and\n",
    "    # run_district_optimization will need.\n",
    "    # We pass them explicitly to avoid relying on global scope within the functions.\n",
    "\n",
    "    for cc_coord_item in top_n_potential_cc:\n",
    "        current_cc_str = f\"start_{cc_coord_item[0]}_{cc_coord_item[1]}\"\n",
    "        print(f\"\\n--- Running Optimization for Starting City Center: {cc_coord_item} ---\")\n",
    "\n",
    "        # 1. Perform pre-calculations for the current city center\n",
    "        # Ensure all necessary global constants are passed to perform_pre_calculations\n",
    "        current_pre_calc_data = perform_pre_calculations(\n",
    "            cc_coords=cc_coord_item,\n",
    "            df_all_tiles=df_map_data,\n",
    "            radius_val=radius_const, # RADIUS from Cell 3\n",
    "            all_districts_list=all_districts_const, # ALL_DISTRICTS from Cell 3\n",
    "            features_dict=features_const, # FEATURES from Cell 3\n",
    "            impassable_terrain_set=impassable_terrain_const, # IMPASSABLE_TERRAIN from Cell 3\n",
    "            impassable_features_set=impassable_features_const, # IMPASSABLE_FEATURES from Cell 3\n",
    "            river_feature_key_str=river_feature_key_const # RIVER_FEATURE_KEY from Cell 3\n",
    "        )\n",
    "\n",
    "        if current_pre_calc_data is None:\n",
    "            print(f\"Skipping CC {cc_coord_item} due to pre-calculation error.\")\n",
    "            location_results[current_cc_str] = {\"status\": \"Error in Precomputation\", \"district_placements\": []}\n",
    "            continue\n",
    "\n",
    "        # 2. Run the optimization\n",
    "        # Ensure all necessary global constants are passed to run_district_optimization\n",
    "        _, _, scenario_result = run_district_optimization(\n",
    "            pre_calc_data=current_pre_calc_data,\n",
    "            all_districts_list=all_districts_const, # ALL_DISTRICTS\n",
    "            district_pair_bonus_dict=district_pair_bonus_const, # DISTRICT_PAIR_BONUS\n",
    "            features_dict=features_const, # FEATURES\n",
    "            district_base_value_dict_global=district_base_value_const, # DISTRICT_BASE_VALUE\n",
    "            cc_bonus_value_dict=cc_bonus_value_const, # CC_BONUS_VALUE\n",
    "            terrain_bonus_value_dict=terrain_bonus_value_const, # TERRAIN_BONUS_VALUE\n",
    "            river_feature_key_str=river_feature_key_const, # RIVER_FEATURE_KEY\n",
    "            districts_unique_list=districts_unique_const, # DISTRICTS_UNIQUE\n",
    "            districts_mutually_exclusive_list=districts_mutually_exclusive_const, # DISTRICTS_MUTUALLY_EXCLUSIVE\n",
    "            max_adjacent_tiles_const=max_adj_tiles_const, # MAX_ADJACENT_TILES\n",
    "            district_values_override=(district_values_override_all if district_values_override_all else None),\n",
    "            scenario_name=current_cc_str\n",
    "        )\n",
    "        location_results[current_cc_str] = scenario_result\n",
    "\n",
    "    return location_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "635334ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_yield_sensitivity_results(results):\n",
    "    \"\"\"Create visualizations for yield sensitivity analysis\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary from run_yield_sensitivity_analysis\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Extract data for visualization\n",
    "    yields = [y for y in results.keys() if y != \"balanced\"]\n",
    "    boost_factors = list(results[yields[0]].keys())\n",
    "    \n",
    "    # Prepare data for objective value comparison\n",
    "    obj_values = []\n",
    "    for yield_type in yields:\n",
    "        yield_values = [results[yield_type][b][\"objective_value\"] for b in boost_factors]\n",
    "        obj_values.append(yield_values)\n",
    "    \n",
    "    balanced_obj = results[\"balanced\"][\"objective_value\"]\n",
    "    \n",
    "    # 1. Objective Value Comparison\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    x = np.arange(len(boost_factors))\n",
    "    width = 0.15\n",
    "    offsets = np.linspace(-0.3, 0.3, len(yields))\n",
    "    \n",
    "    for i, yield_type in enumerate(yields):\n",
    "        plt.bar(x + offsets[i], obj_values[i], width, label=yield_type.capitalize())\n",
    "        \n",
    "    plt.axhline(y=balanced_obj, color='k', linestyle='--', label='Balanced')\n",
    "    \n",
    "    plt.xlabel('Priority Boost Factor')\n",
    "    plt.ylabel('Objective Value')\n",
    "    plt.title('Objective Value by Yield Priority')\n",
    "    plt.xticks(x, boost_factors)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.savefig('yield_priority_objval.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. District Count Comparison\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Count districts for each scenario\n",
    "    district_counts = {}\n",
    "    for yield_type in yields:\n",
    "        district_counts[yield_type] = {}\n",
    "        for boost in boost_factors:\n",
    "            placements = results[yield_type][boost][\"district_placements\"]\n",
    "            counts = {}\n",
    "            for district, _ in placements:\n",
    "                counts[district] = counts.get(district, 0) + 1\n",
    "            district_counts[yield_type][boost] = counts\n",
    "    \n",
    "    # Count balanced districts\n",
    "    balanced_counts = {}\n",
    "    for district, _ in results[\"balanced\"][\"district_placements\"]:\n",
    "        balanced_counts[district] = balanced_counts.get(district, 0) + 1\n",
    "        \n",
    "    # Get unique districts across all scenarios\n",
    "    all_districts = set()\n",
    "    for y in district_counts:\n",
    "        for b in district_counts[y]:\n",
    "            all_districts.update(district_counts[y][b].keys())\n",
    "    all_districts = sorted(all_districts)\n",
    "    \n",
    "    # Create subplots for each yield type\n",
    "    fig, axs = plt.subplots(len(yields), 1, figsize=(12, 4*len(yields)))\n",
    "    \n",
    "    for i, yield_type in enumerate(yields):\n",
    "        ax = axs[i]\n",
    "        district_data = []\n",
    "        \n",
    "        for district in all_districts:\n",
    "            district_data.append([\n",
    "                district_counts[yield_type][b].get(district, 0) - balanced_counts.get(district, 0)\n",
    "                for b in boost_factors\n",
    "            ])\n",
    "        \n",
    "        x = np.arange(len(boost_factors))\n",
    "        width = 0.8 / len(all_districts)\n",
    "        offsets = np.linspace(-0.4, 0.4, len(all_districts))\n",
    "        \n",
    "        for j, district in enumerate(all_districts):\n",
    "            ax.bar(x + offsets[j], district_data[j], width, label=district)\n",
    "            \n",
    "        ax.set_title(f'{yield_type.capitalize()} Priority: District Count Change from Balanced')\n",
    "        ax.set_ylabel('Count Difference')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(boost_factors)\n",
    "        ax.legend(ncol=3)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('yield_priority_districts.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "bc5c1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Ensure numpy is imported\n",
    "\n",
    "def analyze_district_adjacency_patterns(results_dict, all_map_coords_set_param): # Added all_map_coords_set_param\n",
    "    \"\"\"Analyze district adjacency patterns across different scenarios.\n",
    "    Handles both nested (yield-based) and flat (location-based) results_dict structures.\n",
    "    Uses a provided set of all map coordinates to dynamically check adjacencies.\n",
    "    \"\"\"\n",
    "    all_districts_set = set()\n",
    "    processed_scenarios = {}\n",
    "\n",
    "    for scenario_key, scenario_data in results_dict.items():\n",
    "        if isinstance(scenario_data, dict):\n",
    "            if \"district_placements\" in scenario_data and scenario_data.get(\"status\") == GRB.OPTIMAL:\n",
    "                processed_scenarios[scenario_key] = scenario_data[\"district_placements\"]\n",
    "                for district, _ in scenario_data[\"district_placements\"]:\n",
    "                    all_districts_set.add(district)\n",
    "            elif all(isinstance(val, dict) for val in scenario_data.values()):\n",
    "                for boost_factor, nested_scenario_result in scenario_data.items():\n",
    "                    if isinstance(nested_scenario_result, dict) and \\\n",
    "                       \"district_placements\" in nested_scenario_result and \\\n",
    "                       nested_scenario_result.get(\"status\") == GRB.OPTIMAL:\n",
    "                        unique_scenario_name = f\"{scenario_key}_{boost_factor}\"\n",
    "                        processed_scenarios[unique_scenario_name] = nested_scenario_result[\"district_placements\"]\n",
    "                        for district, _ in nested_scenario_result[\"district_placements\"]:\n",
    "                            all_districts_set.add(district)\n",
    "        else:\n",
    "            print(f\"Warning: Skipping scenario '{scenario_key}' as its data is not a dictionary.\")\n",
    "\n",
    "    if not processed_scenarios:\n",
    "        print(\"Warning: No valid scenarios with district placements found in results_dict for adjacency analysis.\")\n",
    "        return {\n",
    "            \"district_types\": [], \"adjacency_matrices\": {}, \"avg_adjacency\": np.array([]),\n",
    "            \"var_adjacency\": np.array([]), \"frequent_pairs\": []\n",
    "        }\n",
    "\n",
    "    all_districts_list = sorted(list(all_districts_set))\n",
    "    n_districts = len(all_districts_list)\n",
    "    \n",
    "    if n_districts == 0:\n",
    "        print(\"Warning: No districts found in any successful scenario placements for adjacency analysis.\")\n",
    "        return {\n",
    "            \"district_types\": [], \"adjacency_matrices\": {}, \"avg_adjacency\": np.array([]),\n",
    "            \"var_adjacency\": np.array([]), \"frequent_pairs\": []\n",
    "        }\n",
    "\n",
    "    adjacency_matrices_dict = {}\n",
    "    for scenario_name, placements in processed_scenarios.items():\n",
    "        if not placements:\n",
    "            print(f\"Info: Scenario '{scenario_name}' had no district placements, skipping for adjacency matrix.\")\n",
    "            continue\n",
    "\n",
    "        coord_to_district = {coords: district for district, coords in placements}\n",
    "        adj_matrix = np.zeros((n_districts, n_districts))\n",
    "\n",
    "        for district1, coords1 in placements:\n",
    "            if district1 not in all_districts_list: continue\n",
    "            idx1 = all_districts_list.index(district1)\n",
    "            \n",
    "            # Dynamically find neighbors using the full map coordinate set\n",
    "            for adj_coords_candidate in get_adjacent_tiles(coords1[0], coords1[1], all_map_coords_set_param):\n",
    "                if adj_coords_candidate in coord_to_district: # Check if this neighbor has a placed district in THIS scenario\n",
    "                    district2 = coord_to_district[adj_coords_candidate]\n",
    "                    if district2 not in all_districts_list: continue\n",
    "                    idx2 = all_districts_list.index(district2)\n",
    "                    adj_matrix[idx1, idx2] += 1 # Counts D1 -> D2 adjacency\n",
    "        \n",
    "        adjacency_matrices_dict[scenario_name] = adj_matrix\n",
    "\n",
    "    if not adjacency_matrices_dict:\n",
    "        raise ValueError(\"No valid adjacency matrices could be created from the processed scenarios (post-filtering).\")\n",
    "        \n",
    "    matrix_list_for_stats = list(adjacency_matrices_dict.values())\n",
    "    avg_adjacency = np.mean(matrix_list_for_stats, axis=0)\n",
    "    var_adjacency = np.var(matrix_list_for_stats, axis=0)\n",
    "    \n",
    "    frequent_pairs = []\n",
    "    for i in range(n_districts):\n",
    "        for j in range(n_districts): # Iterate all pairs to make matrix symmetric for CV, or decide on directedness\n",
    "            # For frequent pairs list, often we consider (D1, D2) and (D2, D1) as the same undirected pairing.\n",
    "            # The heatmap will show directed avg_adjacency[i,j].\n",
    "            # For the frequent_pairs list, let's make it unique pairs (i < j).\n",
    "            if i >= j: continue\n",
    "\n",
    "            # We need to decide how to represent the \"average frequency\" and \"variance\" for an undirected pair.\n",
    "            # Option 1: avg_adj[i,j] and var_adj[i,j] (as in previous version)\n",
    "            # Option 2: (avg_adj[i,j] + avg_adj[j,i])/2 and related combined variance.\n",
    "            # Sticking to previous logic for frequent_pairs list to keep it simple for now (uses i,j where i < j implicitly by range)\n",
    "            # but for CV matrix in heatmap, it uses the full matrix.\n",
    "            \n",
    "            # For the frequent_pairs list, let's use the i,j entry where i < j (from the sorted all_districts_list)\n",
    "            # This ensures each pair is listed once.\n",
    "            current_avg_freq = avg_adjacency[i, j] \n",
    "            current_var = var_adjacency[i, j]\n",
    "            \n",
    "            # To make the \"frequent_pairs\" list reflect overall adjacency (D1 near D2 or D2 near D1 for the pair):\n",
    "            # One could sum: combined_avg_freq = avg_adjacency[i, j] + avg_adjacency[j, i]\n",
    "            # And combined_var = var_adjacency[i,j] + var_adjacency[j,i] + 2*covariance (more complex)\n",
    "            # Or simply, if either avg_adjacency[i,j] or avg_adjacency[j,i] is high.\n",
    "            # The current heatmap shows avg_adjacency[i,j] which is \"avg times i is adjacent to j\".\n",
    "\n",
    "            if current_avg_freq > 0: # Only add if D_i is found adjacent to D_j on average\n",
    "                frequent_pairs.append({\n",
    "                    \"district1\": all_districts_list[i],\n",
    "                    \"district2\": all_districts_list[j],\n",
    "                    \"avg_frequency\": current_avg_freq,\n",
    "                    \"variance\": current_var,\n",
    "                    \"coefficient_of_variation\": np.sqrt(current_var) / max(current_avg_freq, 1e-6) if current_avg_freq > 1e-7 else np.inf\n",
    "                })\n",
    "    \n",
    "    frequent_pairs.sort(key=lambda x: x[\"avg_frequency\"], reverse=True)\n",
    "    \n",
    "    return {\n",
    "        \"district_types\": all_districts_list,\n",
    "        \"adjacency_matrices\": adjacency_matrices_dict,\n",
    "        \"avg_adjacency\": avg_adjacency,\n",
    "        \"var_adjacency\": var_adjacency,\n",
    "        \"frequent_pairs\": frequent_pairs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21dcf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def visualize_district_adjacency_patterns(adjacency_data):\n",
    "    \"\"\"Create visualizations for district adjacency patterns, optimized for clarity.\n",
    "\n",
    "    Args:\n",
    "        adjacency_data: Output from analyze_district_adjacency_patterns\n",
    "    \"\"\"\n",
    "    districts = adjacency_data[\"district_types\"]\n",
    "    avg_adjacency = adjacency_data[\"avg_adjacency\"]\n",
    "    var_adjacency = adjacency_data[\"var_adjacency\"]\n",
    "\n",
    "    # --- 1. Average Adjacency Frequency Heatmap ---\n",
    "    # More intuitive title and colormap\n",
    "    fig_avg, ax_avg = plt.subplots(figsize=(13, 11)) # Slightly larger figure\n",
    "    sns.heatmap(\n",
    "        avg_adjacency,\n",
    "        annot=True, # Keep annotations for specific values\n",
    "        fmt=\".1f\",  # Keep one decimal place for precision\n",
    "        cmap=\"Blues\", # Simple, sequential colormap (Light blue = less frequent, Dark blue = more frequent)\n",
    "        linewidths=.5, # Add lines between cells\n",
    "        linecolor='lightgray',\n",
    "        cbar_kws={'label': 'Average Number of Times Adjacent'}, # Clearer color bar label\n",
    "        xticklabels=districts,\n",
    "        yticklabels=districts,\n",
    "        ax=ax_avg\n",
    "    )\n",
    "    ax_avg.set_title(\n",
    "        \"How Often are District Types Placed Next to Each Other? (On Average)\",\n",
    "        fontsize=16, pad=20 # Larger, clearer title with padding\n",
    "    )\n",
    "    ax_avg.set_xlabel(\"Adjacent District Type\", fontsize=12)\n",
    "    ax_avg.set_ylabel(\"District Type\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right') # Improve label readability\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to prevent title overlap\n",
    "    plt.savefig('district_adjacency_avg_improved.png', dpi=150) # Save with higher DPI\n",
    "    plt.close(fig_avg)\n",
    "    print(\"Saved improved average adjacency heatmap.\")\n",
    "\n",
    "    # --- 2. Adjacency Variability Heatmap ---\n",
    "    # Focus on explaining the variability concept clearly\n",
    "    fig_var, ax_var = plt.subplots(figsize=(13, 11))\n",
    "\n",
    "    # Calculate Coefficient of Variation (CV) - Higher means more variation relative to the average\n",
    "    cv_matrix = np.zeros_like(avg_adjacency)\n",
    "    non_zero_mask = avg_adjacency > 0\n",
    "    # Calculate CV only where average is non-zero to avoid division by zero\n",
    "    cv_matrix[non_zero_mask] = np.sqrt(var_adjacency[non_zero_mask]) / avg_adjacency[non_zero_mask]\n",
    "\n",
    "    # Determine a reasonable maximum for the color scale to avoid outliers dominating\n",
    "    # Using the 95th percentile might be more robust than the absolute max\n",
    "    vmax_val = np.percentile(cv_matrix[non_zero_mask], 95) if np.any(non_zero_mask) else 1.0\n",
    "\n",
    "    sns.heatmap(\n",
    "        cv_matrix,\n",
    "        annot=True, # Annotate with the CV value\n",
    "        fmt=\".2f\",  # Two decimal places for CV\n",
    "        cmap=\"OrRd\", # Sequential orange-red (Light = less variable, Dark Red = more variable)\n",
    "        linewidths=.5,\n",
    "        linecolor='lightgray',\n",
    "        cbar_kws={'label': 'Variability'},\n",
    "        xticklabels=districts,\n",
    "        yticklabels=districts,\n",
    "        ax=ax_var,\n",
    "        vmin=0, # Variability starts at 0\n",
    "        vmax=vmax_val # Set a max value for the color scale\n",
    "    )\n",
    "    ax_var.set_title(\n",
    "        \"District Pair Placement Sensitivity Based on City Location\\n(High Variability = Pair Placement Sensitive to Starting City Location)\",\n",
    "        fontsize=16, pad=20\n",
    "    )\n",
    "    ax_var.set_xlabel(\"Adjacent District Type\", fontsize=12)\n",
    "    ax_var.set_ylabel(\"District Type\", fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.savefig('district_adjacency_variability_improved.png', dpi=150)\n",
    "    plt.close(fig_var)\n",
    "    print(\"Saved improved adjacency variability heatmap.\")\n",
    "\n",
    "\n",
    "    # --- 3. Top District Pairs Bar Chart ---\n",
    "    # This chart already had some good features for non-technical audiences (color coding)\n",
    "    # Minor tweaks for clarity\n",
    "    if \"frequent_pairs\" in adjacency_data and adjacency_data[\"frequent_pairs\"]:\n",
    "        # Keep only pairs that occur, on average (avoids pairs that only appear in one scenario)\n",
    "        frequent_pairs = [p for p in adjacency_data[\"frequent_pairs\"] if p[\"avg_frequency\"] > 0.1][:10] # Top 10\n",
    "\n",
    "        if not frequent_pairs:\n",
    "            print(\"Warning: No frequent pairs with avg_frequency > 0.1 found for bar chart.\")\n",
    "            return # Exit if no valid pairs\n",
    "\n",
    "        fig_bar, ax_bar = plt.subplots(figsize=(14, 9)) # Adjusted size\n",
    "\n",
    "        # Sort pairs by Coefficient of Variation for consistent color mapping in the plot\n",
    "        # Low CV (consistent, green) on left, High CV (variable, red) on right\n",
    "        frequent_pairs.sort(key=lambda x: x[\"coefficient_of_variation\"])\n",
    "\n",
    "        labels = [f\"{p['district1']} - {p['district2']}\" for p in frequent_pairs]\n",
    "        values = [p[\"avg_frequency\"] for p in frequent_pairs]\n",
    "        errors = [np.sqrt(p[\"variance\"]) for p in frequent_pairs]\n",
    "        cv_values = [p[\"coefficient_of_variation\"] for p in frequent_pairs]\n",
    "\n",
    "        # Define the color map (Green=Consistent/Low CV, Red=Variable/High CV)\n",
    "        # Handle cases where all CVs might be very low or very high\n",
    "        min_cv = min(cv_values) if cv_values else 0\n",
    "        max_cv = max(cv_values) if cv_values else 1\n",
    "        if max_cv == min_cv: # Avoid division by zero if all values are the same\n",
    "             max_cv = min_cv + 0.1\n",
    "\n",
    "        # Normalize CV values for colormapping\n",
    "        norm = mcolors.Normalize(vmin=min_cv, vmax=max_cv)\n",
    "        cmap = plt.cm.RdYlGn_r # Red=High, Yellow=Mid, Green=Low Variability\n",
    "\n",
    "        colors = cmap(norm(cv_values))\n",
    "\n",
    "        bars = ax_bar.bar(range(len(frequent_pairs)), values, yerr=errors, capsize=5, color=colors)\n",
    "\n",
    "        ax_bar.set_xticks(range(len(frequent_pairs)))\n",
    "        ax_bar.set_xticklabels(labels, rotation=45, ha='right', fontsize=11)\n",
    "        ax_bar.set_ylabel(\"Average Adjacency Frequency\", fontsize=12)\n",
    "        ax_bar.set_title(\n",
    "            \"Top 10 Most Frequent District Pairings\\n(Color indicates consistency across strategies: Green=Consistent, Red=Varies)\",\n",
    "            fontsize=14, pad=15\n",
    "        )\n",
    "\n",
    "        # Add color bar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([]) # Necessary for mappable\n",
    "        cbar = plt.colorbar(sm, ax=ax_bar, pad=0.02)\n",
    "        cbar.set_label(\"Strategy Sensitivity (Variability)\", rotation=270, labelpad=20, fontsize=12)\n",
    "\n",
    "        # Add grid for easier reading\n",
    "        ax_bar.yaxis.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.05, 1, 0.95]) # Adjust layout\n",
    "        plt.savefig('district_adjacency_top_pairs_improved.png', dpi=150)\n",
    "        plt.close(fig_bar)\n",
    "        print(\"Saved improved top pairs bar chart.\")\n",
    "    else:\n",
    "        print(\"Warning: No frequent pairs data available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "b2471c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Starting Location Sensitivity Analysis ===\n",
      "\n",
      "--- Running Optimization for Starting City Center: (56, 25) ---\n",
      "For CC at (56, 25): Total tiles in radius 3: 37\n",
      "For CC at (56, 25): Workable tiles in radius: 29\n",
      "For CC at (56, 25): Tiles with river edges: 10\n",
      "For CC at (56, 25): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 12 tiles with scenario_start_56_25\n",
      "\n",
      "--- Running Optimization for Starting City Center: (11, 23) ---\n",
      "For CC at (11, 23): Total tiles in radius 3: 37\n",
      "For CC at (11, 23): Workable tiles in radius: 35\n",
      "For CC at (11, 23): Tiles with river edges: 11\n",
      "For CC at (11, 23): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 12 tiles with scenario_start_11_23\n",
      "\n",
      "--- Running Optimization for Starting City Center: (45, 31) ---\n",
      "For CC at (45, 31): Total tiles in radius 3: 37\n",
      "For CC at (45, 31): Workable tiles in radius: 27\n",
      "For CC at (45, 31): Tiles with river edges: 13\n",
      "For CC at (45, 31): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 10 tiles with scenario_start_45_31\n",
      "\n",
      "--- Running Optimization for Starting City Center: (52, 27) ---\n",
      "For CC at (52, 27): Total tiles in radius 3: 37\n",
      "For CC at (52, 27): Workable tiles in radius: 22\n",
      "For CC at (52, 27): Tiles with river edges: 14\n",
      "For CC at (52, 27): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 10 tiles with scenario_start_52_27\n",
      "\n",
      "--- Running Optimization for Starting City Center: (17, 18) ---\n",
      "For CC at (17, 18): Total tiles in radius 3: 37\n",
      "For CC at (17, 18): Workable tiles in radius: 36\n",
      "For CC at (17, 18): Tiles with river edges: 9\n",
      "For CC at (17, 18): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 10 tiles with scenario_start_17_18\n",
      "\n",
      "--- Running Optimization for Starting City Center: (56, 26) ---\n",
      "For CC at (56, 26): Total tiles in radius 3: 37\n",
      "For CC at (56, 26): Workable tiles in radius: 29\n",
      "For CC at (56, 26): Tiles with river edges: 12\n",
      "For CC at (56, 26): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 12 tiles with scenario_start_56_26\n",
      "\n",
      "--- Running Optimization for Starting City Center: (51, 22) ---\n",
      "For CC at (51, 22): Total tiles in radius 3: 37\n",
      "For CC at (51, 22): Workable tiles in radius: 36\n",
      "For CC at (51, 22): Tiles with river edges: 14\n",
      "For CC at (51, 22): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 11 tiles with scenario_start_51_22\n",
      "\n",
      "--- Running Optimization for Starting City Center: (48, 23) ---\n",
      "For CC at (48, 23): Total tiles in radius 3: 37\n",
      "For CC at (48, 23): Workable tiles in radius: 36\n",
      "For CC at (48, 23): Tiles with river edges: 24\n",
      "For CC at (48, 23): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 11 tiles with scenario_start_48_23\n",
      "\n",
      "--- Running Optimization for Starting City Center: (9, 10) ---\n",
      "For CC at (9, 10): Total tiles in radius 3: 37\n",
      "For CC at (9, 10): Workable tiles in radius: 36\n",
      "For CC at (9, 10): Tiles with river edges: 19\n",
      "For CC at (9, 10): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 12 tiles with scenario_start_9_10\n",
      "\n",
      "--- Running Optimization for Starting City Center: (13, 19) ---\n",
      "For CC at (13, 19): Total tiles in radius 3: 37\n",
      "For CC at (13, 19): Workable tiles in radius: 36\n",
      "For CC at (13, 19): Tiles with river edges: 5\n",
      "For CC at (13, 19): Pre-calculation of boolean maps finished.\n",
      "Updated JSON: 11 tiles with scenario_start_13_19\n",
      "\n",
      "--- Analyzing Adjacency Patterns for Location Sensitivity ---\n",
      "\n",
      "--- Visualizing Adjacency Patterns for Location Sensitivity ---\n",
      "Saved improved average adjacency heatmap.\n",
      "Saved improved adjacency variability heatmap.\n",
      "Saved improved top pairs bar chart.\n",
      "\n",
      "Most consistent district pairings across starting locations:\n",
      "  Canal - Industrial Zone: avg_freq=1.00 (CV: 0.000)\n",
      "  Aqueduct - Industrial Zone: avg_freq=0.90 (CV: 0.333)\n",
      "  Campus - Holy Site: avg_freq=0.90 (CV: 0.333)\n",
      "  Commercial Hub - Government Plaza: avg_freq=0.80 (CV: 0.500)\n",
      "  Commercial Hub - Industrial Zone: avg_freq=0.70 (CV: 0.655)\n",
      "  Campus - Theater Square: avg_freq=0.70 (CV: 0.655)\n",
      "  Commercial Hub - Theater Square: avg_freq=0.70 (CV: 0.655)\n",
      "  Holy Site - Theater Square: avg_freq=0.60 (CV: 0.816)\n",
      "  Campus - Government Plaza: avg_freq=0.60 (CV: 0.816)\n",
      "  Dam - Industrial Zone: avg_freq=0.60 (CV: 0.816)\n"
     ]
    }
   ],
   "source": [
    "# --- Run Location Sensitivity Analysis ---\n",
    "# Make sure all constants are defined in Cell 3 or passed correctly from their origin.\n",
    "# df is loaded in Cell 2\n",
    "# potential_city_centers is defined in Cell 2 (modified)\n",
    "\n",
    "# Ensure RADIUS, ALL_DISTRICTS, FEATURES, IMPASSABLE_TERRAIN, IMPASSABLE_FEATURES,\n",
    "# RIVER_FEATURE_KEY, DISTRICT_PAIR_BONUS, DISTRICT_BASE_VALUE, CC_BONUS_VALUE,\n",
    "# TERRAIN_BONUS_VALUE, DISTRICTS_UNIQUE, DISTRICTS_MUTUALLY_EXCLUSIVE, MAX_ADJACENT_TILES\n",
    "# are accessible here (they are global in your notebook).\n",
    "\n",
    "if potential_city_centers: # Check if we have city centers to test\n",
    "    print(\"\\n\\n=== Starting Location Sensitivity Analysis ===\")\n",
    "    location_sensitivity_results = run_location_sensitivity_analysis(\n",
    "        top_n_potential_cc=potential_city_centers, # From modified Cell 2\n",
    "        df_map_data=df,                            # From Cell 2\n",
    "        radius_const=RADIUS,\n",
    "        all_districts_const=ALL_DISTRICTS,\n",
    "        features_const=FEATURES,\n",
    "        impassable_terrain_const=IMPASSABLE_TERRAIN,\n",
    "        impassable_features_const=IMPASSABLE_FEATURES,\n",
    "        river_feature_key_const=RIVER_FEATURE_KEY,\n",
    "        district_pair_bonus_const=DISTRICT_PAIR_BONUS,\n",
    "        district_base_value_const=DISTRICT_BASE_VALUE, # The global one\n",
    "        cc_bonus_value_const=CC_BONUS_VALUE,\n",
    "        terrain_bonus_value_const=TERRAIN_BONUS_VALUE,\n",
    "        districts_unique_const=DISTRICTS_UNIQUE,\n",
    "        districts_mutually_exclusive_const=DISTRICTS_MUTUALLY_EXCLUSIVE,\n",
    "        max_adj_tiles_const=MAX_ADJACENT_TILES\n",
    "        # If you want to test location sensitivity under a specific yield profile (e.g., balanced),\n",
    "        # you can pass 'district_values_override_all=create_priority_profile(...)' or a fixed dict.\n",
    "        # For now, it uses the default DISTRICT_BASE_VALUE.\n",
    "    )\n",
    "    if location_sensitivity_results and potential_city_centers:\n",
    "        print(\"\\n--- Analyzing Adjacency Patterns for Location Sensitivity ---\")\n",
    "\n",
    "        adapted_location_results_for_analysis = {}\n",
    "        for key, value in location_sensitivity_results.items():\n",
    "            adapted_location_results_for_analysis[key] = value\n",
    "\n",
    "        # Get the global all_map_coords which should have been defined in Cell 5 (now 88c94a50)\n",
    "        if 'all_map_coords' not in globals():\n",
    "            print(\"ERROR: global 'all_map_coords' not found. It should be defined from the main pre-calculation cell.\")\n",
    "            global all_map_coords \n",
    "            if 'df' in globals() and 'all_map_coords' not in globals(): \n",
    "                 all_map_coords = set((int(coord[0]), int(coord[1])) for coord in df[['x', 'y']].values)\n",
    "                 print(\"Re-derived all_map_coords for analysis function.\")\n",
    "            elif 'all_map_coords' not in globals():\n",
    "                 print(\"CRITICAL ERROR: Cannot proceed without all_map_coords.\")\n",
    "                 # Consider exiting or raising an error here if all_map_coords is truly necessary and missing\n",
    "\n",
    "        # Ensure all_map_coords is available before calling\n",
    "        if 'all_map_coords' in globals() and all_map_coords: # Check it's defined and not empty\n",
    "            location_adjacency_analysis = analyze_district_adjacency_patterns(\n",
    "                adapted_location_results_for_analysis,\n",
    "                all_map_coords # Pass the full set of map coordinates\n",
    "            )\n",
    "\n",
    "            print(\"\\n--- Visualizing Adjacency Patterns for Location Sensitivity ---\")\n",
    "            visualize_district_adjacency_patterns(location_adjacency_analysis)\n",
    "\n",
    "            print(\"\\nMost consistent district pairings across starting locations:\")\n",
    "            sorted_by_consistency_loc = sorted(\n",
    "                location_adjacency_analysis[\"frequent_pairs\"],\n",
    "                key=lambda x: x[\"coefficient_of_variation\"]\n",
    "            )\n",
    "            for pair_loc in sorted_by_consistency_loc[:10]: # Show top 10\n",
    "                print(f\"  {pair_loc['district1']} - {pair_loc['district2']}: avg_freq={pair_loc['avg_frequency']:.2f} (CV: {pair_loc['coefficient_of_variation']:.3f})\")\n",
    "        else:\n",
    "             print(\"Skipping adjacency analysis because 'all_map_coords' was not available.\")\n",
    "    else:\n",
    "        print(\"No potential city centers were found or processed. Skipping location sensitivity analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
